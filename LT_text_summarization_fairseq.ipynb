{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_summarization_fairseq.ipynb","provenance":[{"file_id":"1xd8zeHL6F2nbupRU9OfBHHWUDrU2mtbX","timestamp":1617254528840},{"file_id":"155S_bb3viIoL0wAwkIyr1r8XQu4ARwA9","timestamp":1614589209910}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHwXrnurigIi","executionInfo":{"status":"ok","timestamp":1621078823769,"user_tz":-180,"elapsed":20646,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"fd9f622e-313f-423a-88be-d663cfc8d151"},"source":["import os\n","from google.colab import files\n","import pandas as pd\n","\n","#uploaded = files.upload()\n","\n","#import io\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"olizFKkwOr0N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621078874614,"user_tz":-180,"elapsed":988,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"552dfa7c-6511-47e4-f1ec-8a8abdb11f7d"},"source":["!cd .. && git clone https://github.com/pytorch/fairseq && cd fairseq && git checkout a06083f && pip install --editable ."],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'fairseq'...\n","remote: Enumerating objects: 27847, done.\u001b[K\n","remote: Counting objects: 100% (268/268), done.\u001b[K\n","remote: Compressing objects: 100% (144/144), done.\u001b[K\n","remote: Total 27847 (delta 146), reused 195 (delta 123), pack-reused 27579\u001b[K\n","Receiving objects: 100% (27847/27847), 11.65 MiB | 23.95 MiB/s, done.\n","Resolving deltas: 100% (20965/20965), done.\n","Note: checking out 'a06083f'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by performing another checkout.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -b with the checkout command again. Example:\n","\n","  git checkout -b <new-branch-name>\n","\n","HEAD is now at a06083f8 Fix score reference when using translation_from_pretrained_bart task\n","Obtaining file:///fairseq\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (1.8.1+cu101)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (0.29.23)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (1.14.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (4.41.1)\n","Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==0.9.0) (3.7.4.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==0.9.0) (2.20)\n","Collecting portalocker==2.0.0\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Installing collected packages: portalocker, sacrebleu, fairseq\n","  Running setup.py develop for fairseq\n","Successfully installed fairseq portalocker-2.0.0 sacrebleu-1.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uWdEC4btgbl_"},"source":["# !wget https://dl.fbaipublicfiles.com/fairseq/models/mbart/mbart.CC25.tar.gz \n","# !tar -xzvf mbart.CC25.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nCwO-6iqgkuR"},"source":["#!wget https://dl.fbaipublicfiles.com/laser/WikiMatrix/v1/WikiMatrix.es-lt.tsv.gz "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"39isdKPOh8jt","cellView":"code"},"source":["# #@title Default title text\n","# from tqdm import tqdm, trange\n","# from sklearn.model_selection import train_test_split\n","\n","# es_data = []\n","# lt_data = []\n","\n","# with open(\"/content/drive/MyDrive/vgtu/data/WikiMatrix.es-lt.tsv\") as fp:\n","#     for line in tqdm(fp, total=80000):\n","#         line_data = line.rstrip().split('\\t')\n","#         es_data.append(line_data[1] + '\\n')\n","#         lt_data.append(line_data[2] + '\\n')\n","\n","# total_test = 7000\n","# es_train, es_subtotal, lt_train, lt_subtotal = train_test_split(\n","#         es_data, lt_data, test_size=total_test, random_state=42)\n","\n","# es_test, es_val, lt_test, lt_val = train_test_split(\n","#         es_subtotal, lt_subtotal, test_size=0.5, random_state=42)\n","\n","# file_mapping = {\n","#     'train.es_XX': es_train,\n","#     'train.lt_XX': lt_train,\n","#     'valid.es_XX': es_val,\n","#     'valid.lt_XX': lt_val,\n","#     'test.es_XX': es_test,\n","#    'test.lt_XX': lt_test,\n","\n","# }\n","\n","\n","# for k, v in file_mapping.items():\n","#     with open(f'/content/drive/MyDrive/vgtu/data/preprocessed/{k}', 'w+') as fp:\n","#         fp.writelines(v)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LboLv73i5je","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621068170403,"user_tz":-180,"elapsed":3163,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"2b0a288f-d4f5-4bc3-f256-819e6cd8c481"},"source":["!pip install sentencepiece\n","import os\n","import sentencepiece as spm\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\r\u001b[K     |▎                               | 10kB 23.7MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 29.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 33.8MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 27.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 22.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 19.0MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 20.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 20.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 19.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 20.7MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 20.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 20.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 20.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 20.7MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 20.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 20.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 20.7MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qiLUafmUslF2","executionInfo":{"status":"ok","timestamp":1621068707150,"user_tz":-180,"elapsed":1246,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"dca4329d-2cb0-416c-a026-a9a678fb5739"},"source":["sp = spm.SentencePieceProcessor()\n","sp.load(\"/content/drive/MyDrive/mbart.cc25.v2/sentence.bpe.model\")\n"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"CR8YA8l1rdpB","executionInfo":{"status":"ok","timestamp":1621069078674,"user_tz":-180,"elapsed":581,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}}},"source":["#SPM=/usr/local/bin/spm_encode\n","#MODEL=/content/mbart.cc25/sentence.bpe.model\n","DATA=\"/content/drive/MyDrive/preprocessed\"\n","\n","train_path = \"{}/train.csv\".format(DATA)\n","test_path = \"{}/test.csv\".format(DATA)\n","val_path = \"{}/val.csv\".format(DATA)\n","\n","#TRAIN=\"train\"\n","#VALID=\"valid\"\n","#TEST=\"test\"\n","#SRC=\"es_XX\"\n","#TGT=\"lt_XX\"\n","\n","source_suffix='bpe.en_XX'\n","target_suffix='bpe.lt_LT'\n","out_dir=\"/content/drive/MyDrive//postprocessed/\""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hcd_c8sftDEP","executionInfo":{"status":"ok","timestamp":1621069082450,"user_tz":-180,"elapsed":738,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}}},"source":["train_text_file = os.path.join(out_dir, \"train.{}\".format(source_suffix))\n","train_summary_file = os.path.join(out_dir, \"train.{}\".format(target_suffix))\n","val_text_file = os.path.join(out_dir, \"val.{}\".format(source_suffix))\n","val_summary_file = os.path.join(out_dir, \"val.{}\".format(target_suffix))\n","test_text_file = os.path.join(out_dir, \"test.{}\".format(source_suffix))\n","test_summary_file = os.path.join(out_dir, \"test.{}\".format(target_suffix))"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"9txLHSMItNJS","executionInfo":{"status":"ok","timestamp":1621069083780,"user_tz":-180,"elapsed":600,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}}},"source":["lowercase=False\n","max_text_subwords=600\n","max_summary_subwords=160\n","insert_tags=False\n"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"6J07-ru3v0Y3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621069127013,"user_tz":-180,"elapsed":42185,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"dee776f2-e382-481c-d3f8-236f3b2bae20"},"source":["import pandas as pd\n","\n","files = ((train_path, train_text_file, train_summary_file),\n","         (val_path, val_text_file, val_summary_file),\n","         (test_path, test_text_file, test_summary_file))\n","\n","\n","i=0\n","for path, text_file_name, summary_file_name in files:\n","    with open(text_file_name, \"w\") as text_file, open(summary_file_name, \"w\") as summary_file:\n","        d = pd.read_csv(path, sep='\\t') \n","        df = zip(d['text'].to_list(), d['summary'].to_list())\n","        for text, summary in df:\n","            if lowercase:\n","                text = text.lower()\n","                summary = summary.lower()\n","            text_subwords = sp.EncodeAsPieces(text)\n","            if max_text_subwords:\n","                text_subwords = text_subwords[:max_text_subwords]\n","                if i == 1:\n","                  print(\"#### TEXT ####\")\n","                  print(text_subwords)\n","                  if len(text_subwords) > 599:\n","                    print(i)\n","                    print(len(text_subwords))\n","                    print(text_subwords)\n","            summary_subwords = sp.EncodeAsPieces(summary)\n","            if max_summary_subwords:\n","                summary_subwords = summary_subwords[:max_summary_subwords]\n","                if i == 1:\n","                  print(\"####### summary ############\")\n","                  print(summary_subwords)\n","            if insert_tags:\n","                text_subwords.insert(0, \"<t>\")\n","                text_subwords.append(\"</t>\")\n","                summary_subwords.insert(0, \"<t>\")\n","                summary_subwords.append(\"</t>\")\n","            text_file.write(\" \".join(text_subwords) + \"\\n\")\n","            summary_file.write((\" \".join(summary_subwords)) + \"\\n\")\n","            i+=1\n","            "],"execution_count":35,"outputs":[{"output_type":"stream","text":["#### TEXT ####\n","['▁Pasak', '▁VM', 'VT', '▁specialist', 'ės', '▁Il', 'ono', 's', '▁Dru', 'ly', 'tės', ',', '▁pagrindinė', '▁priežastis', ',', '▁kodėl', '▁iš', 'meta', 'me', '▁tiek', '▁daug', '▁vartoti', '▁tinka', 'mų', '▁maisto', '▁produktų', ',', '▁–', '▁ne', 'supra', 'n', 'tame', '▁ant', '▁pak', 'uočių', '▁nurody', 'tų', '▁gali', 'o', 'jimo', '▁termin', 'ų', '▁reikšmė', 's', '.', '„', 'Nu', 'stato', 'mos', '▁dviejų', '▁rūši', 'ų', '▁maisto', '▁produktų', '▁gali', 'o', 'jimo', '▁termino', '▁pabaigos', '▁datos', '▁–', '▁„', 'tinka', '▁vartoti', '▁iki', '“', '▁arba', '▁„', 'ger', 'iausias', '▁iki', '“.', '▁Angli', 'ška', 'i', '▁jos', '▁vadina', 'si', '▁„', 'use', '▁by', '“', '▁arba', '▁„', 'best', '▁before', '“', '▁–', '▁tai', '▁svarbu', 's', '▁Europos', '▁Sąjungos', '▁teisės', '▁reik', 'al', 'avimas', '.', '▁Ki', 'to', 'kio', '▁ver', 'timo', '▁ir', '▁interpretacij', 'os', '▁negali', '▁būti', ',', '▁nes', '▁termina', 'i', '▁iš', '▁es', 'mės', '▁skiria', 'si', '“,', '▁–', '▁sako', '▁I', '.', '▁Dr', 'ul', 'ytė', '.', 'Gal', 'io', 'jimo', '▁laiką', ',', '▁kuris', '▁turi', '▁būti', '▁įvertin', 'tas', '▁laborator', 'iniais', '▁tyrimai', 's', ',', '▁nu', 'stato', '▁produkto', '▁gamin', 'toja', 's', ':', '▁„', 'Pa', 'grind', 'inį', '▁skirt', 'umą', '▁nu', 'sako', '▁patys', '▁žodžiai', '▁–', '▁„', 'tinka', '▁vartoti', '▁iki', '“', '▁nur', 'o', 'doma', '▁greitai', '▁ge', 'nda', 'ntiems', '▁maisto', '▁produkt', 'ams', '.', '▁Šiam', '▁terminu', 'i', '▁pasi', 'baig', 'us', ',', '▁maisto', '▁produktai', '▁yra', '▁nes', 'aug', 'ūs', ',', '▁jų', '▁vartoti', '▁ne', 'reik', 'ėtų', '.', '▁Pa', 'prast', 'ai', '▁to', 'kiem', 's', '▁produkt', 'ams', '▁dar', '▁nurody', 'tos', '▁ir', '▁speciali', 'os', '▁laik', 'ymo', '▁sąlygos', '.', '▁Da', 'ž', 'n', 'iausiai', '▁juos', '▁pa', 'taria', 'ma', '▁laikyti', '▁šal', 'dy', 'tu', 've', '“,', '▁–', '▁teigia', '▁I', '.', '▁Dr', 'ul', 'ytė', '.', 'Gal', 'io', 'jimo', '▁termin', 'ą', '▁„', 'tinka', '▁vartoti', '▁iki', '“,', '▁pasak', '▁specialist', 'ės', ',', '▁dažniausiai', '▁ra', 'sime', '▁ant', '▁tokių', '▁produktų', ',', '▁kaip', '▁mė', 'sa', '▁ir', '▁mal', 'ta', '▁mė', 'sa', ',', '▁pieno', '▁produktai', ',', '▁iš', 'sky', 'rus', '▁konserv', 'u', 'otus', ',', '▁įvair', 'ūs', '▁pus', 'gam', 'iniai', '.', 'I', '.', '▁Dr', 'ul', 'ytė', '▁prime', 'na', ',', '▁kad', '▁gali', 'o', 'jimo', '▁termina', 's', '▁„', 'ger', 'iausias', '▁iki', '“', '▁nu', 'sako', '▁ne', '▁produkto', '▁sau', 'g', 'umą', '▁vartoti', ',', '▁o', '▁gali', 'mą', '▁kok', 'yb', 'inių', '▁sav', 'ybių', '▁pak', 'it', 'imą', ':', '▁„', 'Ter', 'mina', 's', '▁„', 'ger', 'iausias', '▁iki', '“', '▁literat', 'ūr', 'oje', '▁dar', '▁kartais', '▁vadina', 'mas', '▁minimal', 'iu', '▁tinka', 'mu', 'mo', '▁vartoti', '▁terminu', '.', '▁Jis', '▁reiškia', ',', '▁kad', '▁iki', '▁šios', '▁datos', '▁produkt', 'as', '▁vartoti', '▁tikrai', '▁gera', 's', ',', '▁o', '▁vėliau', '▁jo', '▁kok', 'ybinė', 's', '▁sav', 'ybės', '▁gali', '▁supra', 'st', 'ėti', ',', '▁tačiau', '▁jį', '▁sau', 'gu', '▁vartoti', '.', 'Ga', 'min', 'toja', 's', '▁garant', 'uoja', ',', '▁kad', '▁iki', '▁nurody', 'to', '▁termino', '▁produkt', 'as', '▁atitinka', '▁visas', '▁deklar', 'uojamas', '▁sa', 'vy', 'bes', '.', '▁Pa', 'prast', 'ai', '▁tai', '▁produktai', ',', '▁kurių', '▁tinka', 'mu', 'mo', '▁vartoti', '▁termina', 'i', '▁ilgi', '.', '▁Da', 'ž', 'n', 'iausiai', '▁pasi', 'baig', 'us', '▁tokių', '▁produktų', '▁gali', 'o', 'jimo', '▁terminu', 'i', ',', '▁atsiranda', '▁jus', 'l', 'iniai', '▁pak', 'it', 'imai', '.', '▁Pavyzdžiui', ',', '▁nepa', 'že', 'i', 'dus', '▁sau', 's', 'ų', '▁makaron', 'ų', '▁pak', 'uotė', 's', ',', '▁jiems', '▁tikrai', '▁nieko', '▁neat', 'siti', 'ks', '▁ir', '▁bus', '▁tinka', 'mi', '▁vartoti', '.', '▁Ar', 'ba', '▁kava', '▁–', '▁ji', '▁gali', '▁pra', 'rasti', '▁aromat', 'ą', ',', '▁bet', '▁tikrai', '▁nepasi', 'dary', 's', '▁nesa', 'ugi', '.', '▁Taip', '▁pat', '▁ir', '▁konserva', 'i', '.', '“', 'P', 'ix', 'abay', '▁nuotr', '.', 'I', '.', '▁Dr', 'ul', 'ytė', '▁pa', 'b', 'rė', 'žia', ',', '▁kad', '▁kalba', 'ma', '▁tik', '▁apie', '▁produktu', 's', ',', '▁kurių', '▁pak', 'uotė', '▁nepa', 'že', 'ista', '.', '▁Pa', 'že', 'i', 'dus', '▁paku', 'o', 'tę', ',', '▁pasi', 'ke', 'i', 'čia', '▁produkto', '▁aplink', 'a', ':', '▁„', 'Je', 'i', '▁paku', 'o', 'tę', '▁paže', 'id', 'ėme', ',', '▁gali', 'o', 'jimo', '▁termina', 's', '▁jau', '▁kita', 's', '.', '▁Gam', 'into', 'jas', ',', '▁nu', 'staty', 'damas', '▁gali', 'o', 'jimo', '▁termin', 'ą', ',', '▁omen', 'yje', '▁turi', '▁toki', 'ą', '▁paku', 'o', 'tę', ',', '▁kokią', '▁at', 'idu', 'oda', '▁var', 'to', 'to', 'jui', '.', '▁Pak', 'uojant', '▁gali', '▁būti', '▁naudoja', 'mos', '▁du', 'jos', ',', '▁kurios', '▁pake', 'i', 'čia']\n","1\n","600\n","['▁Pasak', '▁VM', 'VT', '▁specialist', 'ės', '▁Il', 'ono', 's', '▁Dru', 'ly', 'tės', ',', '▁pagrindinė', '▁priežastis', ',', '▁kodėl', '▁iš', 'meta', 'me', '▁tiek', '▁daug', '▁vartoti', '▁tinka', 'mų', '▁maisto', '▁produktų', ',', '▁–', '▁ne', 'supra', 'n', 'tame', '▁ant', '▁pak', 'uočių', '▁nurody', 'tų', '▁gali', 'o', 'jimo', '▁termin', 'ų', '▁reikšmė', 's', '.', '„', 'Nu', 'stato', 'mos', '▁dviejų', '▁rūši', 'ų', '▁maisto', '▁produktų', '▁gali', 'o', 'jimo', '▁termino', '▁pabaigos', '▁datos', '▁–', '▁„', 'tinka', '▁vartoti', '▁iki', '“', '▁arba', '▁„', 'ger', 'iausias', '▁iki', '“.', '▁Angli', 'ška', 'i', '▁jos', '▁vadina', 'si', '▁„', 'use', '▁by', '“', '▁arba', '▁„', 'best', '▁before', '“', '▁–', '▁tai', '▁svarbu', 's', '▁Europos', '▁Sąjungos', '▁teisės', '▁reik', 'al', 'avimas', '.', '▁Ki', 'to', 'kio', '▁ver', 'timo', '▁ir', '▁interpretacij', 'os', '▁negali', '▁būti', ',', '▁nes', '▁termina', 'i', '▁iš', '▁es', 'mės', '▁skiria', 'si', '“,', '▁–', '▁sako', '▁I', '.', '▁Dr', 'ul', 'ytė', '.', 'Gal', 'io', 'jimo', '▁laiką', ',', '▁kuris', '▁turi', '▁būti', '▁įvertin', 'tas', '▁laborator', 'iniais', '▁tyrimai', 's', ',', '▁nu', 'stato', '▁produkto', '▁gamin', 'toja', 's', ':', '▁„', 'Pa', 'grind', 'inį', '▁skirt', 'umą', '▁nu', 'sako', '▁patys', '▁žodžiai', '▁–', '▁„', 'tinka', '▁vartoti', '▁iki', '“', '▁nur', 'o', 'doma', '▁greitai', '▁ge', 'nda', 'ntiems', '▁maisto', '▁produkt', 'ams', '.', '▁Šiam', '▁terminu', 'i', '▁pasi', 'baig', 'us', ',', '▁maisto', '▁produktai', '▁yra', '▁nes', 'aug', 'ūs', ',', '▁jų', '▁vartoti', '▁ne', 'reik', 'ėtų', '.', '▁Pa', 'prast', 'ai', '▁to', 'kiem', 's', '▁produkt', 'ams', '▁dar', '▁nurody', 'tos', '▁ir', '▁speciali', 'os', '▁laik', 'ymo', '▁sąlygos', '.', '▁Da', 'ž', 'n', 'iausiai', '▁juos', '▁pa', 'taria', 'ma', '▁laikyti', '▁šal', 'dy', 'tu', 've', '“,', '▁–', '▁teigia', '▁I', '.', '▁Dr', 'ul', 'ytė', '.', 'Gal', 'io', 'jimo', '▁termin', 'ą', '▁„', 'tinka', '▁vartoti', '▁iki', '“,', '▁pasak', '▁specialist', 'ės', ',', '▁dažniausiai', '▁ra', 'sime', '▁ant', '▁tokių', '▁produktų', ',', '▁kaip', '▁mė', 'sa', '▁ir', '▁mal', 'ta', '▁mė', 'sa', ',', '▁pieno', '▁produktai', ',', '▁iš', 'sky', 'rus', '▁konserv', 'u', 'otus', ',', '▁įvair', 'ūs', '▁pus', 'gam', 'iniai', '.', 'I', '.', '▁Dr', 'ul', 'ytė', '▁prime', 'na', ',', '▁kad', '▁gali', 'o', 'jimo', '▁termina', 's', '▁„', 'ger', 'iausias', '▁iki', '“', '▁nu', 'sako', '▁ne', '▁produkto', '▁sau', 'g', 'umą', '▁vartoti', ',', '▁o', '▁gali', 'mą', '▁kok', 'yb', 'inių', '▁sav', 'ybių', '▁pak', 'it', 'imą', ':', '▁„', 'Ter', 'mina', 's', '▁„', 'ger', 'iausias', '▁iki', '“', '▁literat', 'ūr', 'oje', '▁dar', '▁kartais', '▁vadina', 'mas', '▁minimal', 'iu', '▁tinka', 'mu', 'mo', '▁vartoti', '▁terminu', '.', '▁Jis', '▁reiškia', ',', '▁kad', '▁iki', '▁šios', '▁datos', '▁produkt', 'as', '▁vartoti', '▁tikrai', '▁gera', 's', ',', '▁o', '▁vėliau', '▁jo', '▁kok', 'ybinė', 's', '▁sav', 'ybės', '▁gali', '▁supra', 'st', 'ėti', ',', '▁tačiau', '▁jį', '▁sau', 'gu', '▁vartoti', '.', 'Ga', 'min', 'toja', 's', '▁garant', 'uoja', ',', '▁kad', '▁iki', '▁nurody', 'to', '▁termino', '▁produkt', 'as', '▁atitinka', '▁visas', '▁deklar', 'uojamas', '▁sa', 'vy', 'bes', '.', '▁Pa', 'prast', 'ai', '▁tai', '▁produktai', ',', '▁kurių', '▁tinka', 'mu', 'mo', '▁vartoti', '▁termina', 'i', '▁ilgi', '.', '▁Da', 'ž', 'n', 'iausiai', '▁pasi', 'baig', 'us', '▁tokių', '▁produktų', '▁gali', 'o', 'jimo', '▁terminu', 'i', ',', '▁atsiranda', '▁jus', 'l', 'iniai', '▁pak', 'it', 'imai', '.', '▁Pavyzdžiui', ',', '▁nepa', 'že', 'i', 'dus', '▁sau', 's', 'ų', '▁makaron', 'ų', '▁pak', 'uotė', 's', ',', '▁jiems', '▁tikrai', '▁nieko', '▁neat', 'siti', 'ks', '▁ir', '▁bus', '▁tinka', 'mi', '▁vartoti', '.', '▁Ar', 'ba', '▁kava', '▁–', '▁ji', '▁gali', '▁pra', 'rasti', '▁aromat', 'ą', ',', '▁bet', '▁tikrai', '▁nepasi', 'dary', 's', '▁nesa', 'ugi', '.', '▁Taip', '▁pat', '▁ir', '▁konserva', 'i', '.', '“', 'P', 'ix', 'abay', '▁nuotr', '.', 'I', '.', '▁Dr', 'ul', 'ytė', '▁pa', 'b', 'rė', 'žia', ',', '▁kad', '▁kalba', 'ma', '▁tik', '▁apie', '▁produktu', 's', ',', '▁kurių', '▁pak', 'uotė', '▁nepa', 'že', 'ista', '.', '▁Pa', 'že', 'i', 'dus', '▁paku', 'o', 'tę', ',', '▁pasi', 'ke', 'i', 'čia', '▁produkto', '▁aplink', 'a', ':', '▁„', 'Je', 'i', '▁paku', 'o', 'tę', '▁paže', 'id', 'ėme', ',', '▁gali', 'o', 'jimo', '▁termina', 's', '▁jau', '▁kita', 's', '.', '▁Gam', 'into', 'jas', ',', '▁nu', 'staty', 'damas', '▁gali', 'o', 'jimo', '▁termin', 'ą', ',', '▁omen', 'yje', '▁turi', '▁toki', 'ą', '▁paku', 'o', 'tę', ',', '▁kokią', '▁at', 'idu', 'oda', '▁var', 'to', 'to', 'jui', '.', '▁Pak', 'uojant', '▁gali', '▁būti', '▁naudoja', 'mos', '▁du', 'jos', ',', '▁kurios', '▁pake', 'i', 'čia']\n","####### summary ############\n","['▁Tam', '▁tik', 'rų', '▁maisto', '▁produktų', '▁pak', 'uotė', 'se', '▁nurody', 'ta', '▁gali', 'o', 'jimo', '▁termino', '▁pa', 'baig', 'a', '▁„', 'ger', 'iausias', '▁iki', '“', '▁reiškia', ',', '▁kad', '▁iki', '▁šios', '▁datos', '▁produkt', 'as', '▁tikrai', '▁gera', 's', ',', '▁ir', '▁nors', '▁vėliau', '▁jo', '▁sav', 'ybės', '▁gali', '▁supra', 'st', 'ėti', ',', '▁vartoti', '▁jį', '▁vis', '▁dar', '▁sau', 'gu', ',', '▁portalu', 'i', '▁LRT', '.', 'lt', '▁sako', '▁Valstybinė', 's', '▁maisto', '▁ir', '▁veterinar', 'ijos', '▁tarnybos', '▁Mais', 'to', '▁skyriaus', '▁ved', 'ėja', '▁Il', 'ona', '▁Dr', 'ul', 'ytė', '.', '▁Be', 'je', ',', '▁pri', 'du', 'ria', '▁ji', ',', '▁jei', '▁tokių', '▁maisto', '▁produktų', '▁neben', 'ori', 'te', '▁vartoti', '▁patys', ',', '▁Lietuvoje', '▁juos', '▁leidžia', 'ma', '▁pa', 'au', 'koti', '▁labda', 'rai', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c-2C_OVPv0bo","executionInfo":{"status":"ok","timestamp":1621069360080,"user_tz":-180,"elapsed":205634,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"9b86f5d8-d6c2-4bfb-b64e-06513811ad15"},"source":["!python /fairseq/preprocess.py --source-lang \"en_XX\" --target-lang \"lt_LT\" --trainpref \"/content/drive/MyDrive/postprocessed/train.bpe\" --validpref \"/content/drive/MyDrive/postprocessed/val.bpe\" --testpref \"/content/drive/MyDrive/postprocessed/test.bpe\" --destdir \"/content/drive/MyDrive/postprocessed/-bin/\" --workers 60 --srcdict \"/content/drive/MyDrive/mbart.cc25.v2/dict.txt\" --tgtdict \"/content/drive/MyDrive/mbart.cc25.v2/dict.txt\""],"execution_count":36,"outputs":[{"output_type":"stream","text":["2021-05-15 08:59:15 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/content/drive/MyDrive/postprocessed/-bin/', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang='en_XX', srcdict='/content/drive/MyDrive/mbart.cc25.v2/dict.txt', target_lang='lt_LT', task='translation', tensorboard_logdir='', testpref='/content/drive/MyDrive/postprocessed/test.bpe', tgtdict='/content/drive/MyDrive/mbart.cc25.v2/dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='/content/drive/MyDrive/postprocessed/train.bpe', user_dir=None, validpref='/content/drive/MyDrive/postprocessed/val.bpe', workers=60)\n","2021-05-15 08:59:17 | INFO | fairseq_cli.preprocess | [en_XX] Dictionary: 250000 types\n","2021-05-15 09:00:58 | INFO | fairseq_cli.preprocess | [en_XX] /content/drive/MyDrive/postprocessed/train.bpe.en_XX: 40445 sents, 23417754 tokens, 0.000137% replaced by <unk>\n","2021-05-15 09:00:58 | INFO | fairseq_cli.preprocess | [en_XX] Dictionary: 250000 types\n","2021-05-15 09:01:22 | INFO | fairseq_cli.preprocess | [en_XX] /content/drive/MyDrive/postprocessed/val.bpe.en_XX: 5056 sents, 2934081 tokens, 0.000239% replaced by <unk>\n","2021-05-15 09:01:22 | INFO | fairseq_cli.preprocess | [en_XX] Dictionary: 250000 types\n","2021-05-15 09:01:44 | INFO | fairseq_cli.preprocess | [en_XX] /content/drive/MyDrive/postprocessed/test.bpe.en_XX: 5056 sents, 2925184 tokens, 0.000308% replaced by <unk>\n","2021-05-15 09:01:44 | INFO | fairseq_cli.preprocess | [lt_LT] Dictionary: 250000 types\n","2021-05-15 09:02:11 | INFO | fairseq_cli.preprocess | [lt_LT] /content/drive/MyDrive/postprocessed/train.bpe.lt_LT: 40445 sents, 3070862 tokens, 0.0% replaced by <unk>\n","2021-05-15 09:02:11 | INFO | fairseq_cli.preprocess | [lt_LT] Dictionary: 250000 types\n","2021-05-15 09:02:25 | INFO | fairseq_cli.preprocess | [lt_LT] /content/drive/MyDrive/postprocessed/val.bpe.lt_LT: 5056 sents, 382218 tokens, 0.0% replaced by <unk>\n","2021-05-15 09:02:25 | INFO | fairseq_cli.preprocess | [lt_LT] Dictionary: 250000 types\n","2021-05-15 09:02:39 | INFO | fairseq_cli.preprocess | [lt_LT] /content/drive/MyDrive/postprocessed/test.bpe.lt_LT: 5056 sents, 380414 tokens, 0.0% replaced by <unk>\n","2021-05-15 09:02:39 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/drive/MyDrive/postprocessed/-bin/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7MU868sp2w6X"},"source":["# TRAIN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jHlI90b2VNwo","executionInfo":{"status":"ok","timestamp":1621069361056,"user_tz":-180,"elapsed":957,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"0745f841-3dc1-49b7-c6d0-b1fd579022b5"},"source":["!nvidia-smi"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Sat May 15 09:02:40 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ujMKLbkU511"},"source":["# %%writefile setup.sh\n","\n","# export CUDA_HOME=/usr/local/cuda-10.1\n","# git clone https://github.com/NVIDIA/apex\n","# pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"scS7qplYYslf"},"source":["# !sh setup.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EfukHeptzgKH","executionInfo":{"status":"ok","timestamp":1621087493061,"user_tz":-180,"elapsed":3267883,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"dfec6374-5e59-4795-842c-d97d29afcc91"},"source":["# --memory-efficient-fp16 \\\n","MAX_UPDATE=80000\n","WARMUP_UPDATES=500\n","LR=3e-05\n","MAX_TOKENS=603\n","UPDATE_FREQ=2\n","LANGS=\"ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN\"\n","SAVEDIR=\"/content/drive/MyDrive/checkpoint\"\n","DATADIR = \"/content/drive/MyDrive/postprocessed/-bin/\"\n","\n","\n","!python /fairseq/train.py \\\n","  $DATADIR \\\n","  --encoder-normalize-before --decoder-normalize-before \\\n","  --arch mbart_large --layernorm-embedding \\\n","  --task translation_from_pretrained_bart \\\n","  --source-lang en_XX --target-lang lt_LT \\\n","  --ddp-backend=no_c10d \\\n","  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","  --optimizer adam --adam-eps 1e-06 --adam-betas '(0.9, 0.98)' \\\n","  --lr-scheduler polynomial_decay --lr \"$LR\" --warmup-updates \"$WARMUP_UPDATES\" \\\n","  --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 --clip-norm 0.1 \\\n","  --max-update \"$MAX_UPDATE\" \\\n","  --max-tokens \"$MAX_TOKENS\" \\\n","  --required-batch-size-multiple 1 \\\n","  --update-freq \"$UPDATE_FREQ\" \\\n","  --save-interval 1 --save-interval-updates 5000 \\\n","  --keep-interval-updates 1 --no-epoch-checkpoints \\\n","  --seed 42 --log-format simple --log-interval 100 \\\n","  --restore-file \"/content/drive/MyDrive/mbart.cc25.v2/model.pt\" \\\n","  --reset-optimizer --reset-meters --reset-dataloader --reset-lr-scheduler \\\n","  --langs $LANGS \\\n","  --skip-invalid-size-inputs-valid-test \\\n","  --truncate-source \\\n","  --find-unused-parameters \\\n","  --no-last-checkpoints \\\n","  --save-dir $SAVEDIR\n","\n","  ## TRY:\n","\n","    #    --eval-bleu \\\n","    #  --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n","    #  --eval-bleu-detok moses \\\n","    #  --eval-bleu-remove-bpe \\\n","    #  --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\"],"execution_count":8,"outputs":[{"output_type":"stream","text":["2021-05-15 13:10:32 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, best_checkpoint_metric='loss', bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/drive/MyDrive/postprocessed/-bin/', data_buffer_size=0, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=True, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=1, keep_last_epochs=-1, label_smoothing=0.1, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=603, max_tokens_valid=603, max_update=80000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, required_batch_size_multiple=1, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/drive/MyDrive/mbart.cc25.v2/model.pt', save_dir='/content/drive/MyDrive/checkpoint', save_interval=1, save_interval_updates=5000, seed=42, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en_XX', target_lang='lt_LT', task='translation_from_pretrained_bart', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, train_subset='train', truncate_source=True, update_freq=[2], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=500, weight_decay=0.01)\n","2021-05-15 13:10:34 | INFO | fairseq.tasks.translation | [en_XX] dictionary: 250001 types\n","2021-05-15 13:10:34 | INFO | fairseq.tasks.translation | [lt_LT] dictionary: 250001 types\n","2021-05-15 13:10:35 | INFO | fairseq.data.data_utils | loaded 5056 examples from: /content/drive/MyDrive/postprocessed/-bin/valid.en_XX-lt_LT.en_XX\n","2021-05-15 13:10:35 | INFO | fairseq.data.data_utils | loaded 5056 examples from: /content/drive/MyDrive/postprocessed/-bin/valid.en_XX-lt_LT.lt_LT\n","2021-05-15 13:10:35 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/postprocessed/-bin/ valid en_XX-lt_LT 5056 examples\n","2021-05-15 13:10:55 | INFO | fairseq_cli.train | BARTModel(\n","  (encoder): TransformerEncoder(\n","    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n","    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (6): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (7): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (8): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (9): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (10): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (11): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n","    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (6): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (7): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (8): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (9): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (10): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (11): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    (output_projection): Linear(in_features=1024, out_features=250027, bias=False)\n","  )\n","  (classification_heads): ModuleDict()\n",")\n","2021-05-15 13:10:55 | INFO | fairseq_cli.train | model mbart_large, criterion LabelSmoothedCrossEntropyCriterion\n","2021-05-15 13:10:55 | INFO | fairseq_cli.train | num. model params: 610851840 (num. trained: 610851840)\n","2021-05-15 13:11:07 | INFO | fairseq_cli.train | training on 1 GPUs\n","2021-05-15 13:11:07 | INFO | fairseq_cli.train | max tokens per GPU = 603 and max sentences per GPU = None\n","tcmalloc: large alloc 2443411456 bytes == 0x561ec6772000 @  0x7f595cb32b6b 0x7f595cb52379 0x7f58fb78525e 0x7f58fb7869d2 0x7f59397afe7d 0x7f594a3aa120 0x7f5949fe8bd9 0x561dc65108a8 0x561dc6583fd5 0x561dc657e7ad 0x561dc65113ea 0x561dc657f3b5 0x561dc657e7ad 0x561dc6511003 0x561dc6510b09 0x561dc665828d 0x561dc65c71db 0x561dc650fbb1 0x561dc6600fed 0x561dc6583988 0x561dc657e7ad 0x561dc6450e2c 0x561dc6580bb5 0x561dc657e4ae 0x561dc65113ea 0x561dc658032a 0x561dc657e4ae 0x561dc65113ea 0x561dc65837f0 0x561dc657e4ae 0x561dc65113ea\n","tcmalloc: large alloc 2443411456 bytes == 0x561f589aa000 @  0x7f595cb32b6b 0x7f595cb52379 0x7f58fb78525e 0x7f58fb7869d2 0x7f59397afe7d 0x7f594a3aa120 0x7f5949fe8bd9 0x561dc65108a8 0x561dc6583fd5 0x561dc657e7ad 0x561dc65113ea 0x561dc657f3b5 0x561dc657e7ad 0x561dc6511003 0x561dc6510b09 0x561dc665828d 0x561dc65c71db 0x561dc650fbb1 0x561dc6600fed 0x561dc6583988 0x561dc657e7ad 0x561dc6450e2c 0x561dc6580bb5 0x561dc657e4ae 0x561dc65113ea 0x561dc658032a 0x561dc657e4ae 0x561dc65113ea 0x561dc65837f0 0x561dc657e4ae 0x561dc65113ea\n","2021-05-15 13:13:23 | INFO | fairseq.trainer | loaded checkpoint /content/drive/MyDrive/mbart.cc25.v2/model.pt (epoch 142 @ 0 updates)\n","2021-05-15 13:13:23 | INFO | fairseq.trainer | loading train data for epoch 1\n","2021-05-15 13:13:26 | INFO | fairseq.data.data_utils | loaded 40445 examples from: /content/drive/MyDrive/postprocessed/-bin/train.en_XX-lt_LT.en_XX\n","2021-05-15 13:13:26 | INFO | fairseq.data.data_utils | loaded 40445 examples from: /content/drive/MyDrive/postprocessed/-bin/train.en_XX-lt_LT.lt_LT\n","2021-05-15 13:13:26 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/postprocessed/-bin/ train en_XX-lt_LT 40445 examples\n","2021-05-15 13:14:23 | INFO | train_inner | epoch 001:    100 / 20223 loss=14.429, nll_loss=8.23, ppl=300.15, wps=278.7, ups=1.82, wpb=153.6, bsz=2, num_updates=100, lr=6e-06, gnorm=248.12, clip=100, train_wall=55, wall=195\n","2021-05-15 13:15:17 | INFO | train_inner | epoch 001:    200 / 20223 loss=7.409, nll_loss=5.018, ppl=32.41, wps=280.6, ups=1.82, wpb=153.8, bsz=2, num_updates=200, lr=1.2e-05, gnorm=26.54, clip=100, train_wall=54, wall=250\n","2021-05-15 13:16:12 | INFO | train_inner | epoch 001:    300 / 20223 loss=7.098, nll_loss=4.838, ppl=28.61, wps=278.9, ups=1.83, wpb=152.8, bsz=2, num_updates=300, lr=1.8e-05, gnorm=19.997, clip=100, train_wall=54, wall=305\n","2021-05-15 13:17:07 | INFO | train_inner | epoch 001:    400 / 20223 loss=6.84, nll_loss=4.629, ppl=24.74, wps=282.3, ups=1.82, wpb=155.3, bsz=2, num_updates=400, lr=2.4e-05, gnorm=19.03, clip=100, train_wall=54, wall=360\n","2021-05-15 13:18:02 | INFO | train_inner | epoch 001:    500 / 20223 loss=6.692, nll_loss=4.526, ppl=23.04, wps=288.4, ups=1.81, wpb=159.1, bsz=2, num_updates=500, lr=3e-05, gnorm=14.953, clip=100, train_wall=54, wall=415\n","2021-05-15 13:18:57 | INFO | train_inner | epoch 001:    600 / 20223 loss=6.572, nll_loss=4.435, ppl=21.64, wps=289.6, ups=1.82, wpb=159.3, bsz=2, num_updates=600, lr=2.9997e-05, gnorm=16.253, clip=100, train_wall=54, wall=470\n","2021-05-15 13:19:52 | INFO | train_inner | epoch 001:    700 / 20223 loss=6.451, nll_loss=4.336, ppl=20.2, wps=290.3, ups=1.82, wpb=159.8, bsz=2, num_updates=700, lr=2.9994e-05, gnorm=13.499, clip=100, train_wall=54, wall=525\n","2021-05-15 13:20:47 | INFO | train_inner | epoch 001:    800 / 20223 loss=6.367, nll_loss=4.259, ppl=19.14, wps=276.7, ups=1.83, wpb=151, bsz=2, num_updates=800, lr=2.9991e-05, gnorm=13.548, clip=100, train_wall=54, wall=580\n","2021-05-15 13:21:41 | INFO | train_inner | epoch 001:    900 / 20223 loss=6.463, nll_loss=4.389, ppl=20.95, wps=266.1, ups=1.84, wpb=144.7, bsz=2, num_updates=900, lr=2.9988e-05, gnorm=14.44, clip=100, train_wall=54, wall=634\n","2021-05-15 13:22:36 | INFO | train_inner | epoch 001:   1000 / 20223 loss=6.316, nll_loss=4.239, ppl=18.88, wps=279.5, ups=1.83, wpb=152.8, bsz=2, num_updates=1000, lr=2.9985e-05, gnorm=12.397, clip=100, train_wall=54, wall=689\n","2021-05-15 13:23:31 | INFO | train_inner | epoch 001:   1100 / 20223 loss=6.204, nll_loss=4.127, ppl=17.47, wps=289.9, ups=1.82, wpb=159.6, bsz=2, num_updates=1100, lr=2.9982e-05, gnorm=11.485, clip=100, train_wall=54, wall=744\n","2021-05-15 13:24:26 | INFO | train_inner | epoch 001:   1200 / 20223 loss=6.23, nll_loss=4.174, ppl=18.05, wps=281.7, ups=1.82, wpb=154.8, bsz=2, num_updates=1200, lr=2.9979e-05, gnorm=12.211, clip=100, train_wall=54, wall=799\n","2021-05-15 13:25:21 | INFO | train_inner | epoch 001:   1300 / 20223 loss=6.194, nll_loss=4.15, ppl=17.76, wps=281.2, ups=1.83, wpb=153.4, bsz=2, num_updates=1300, lr=2.9976e-05, gnorm=11.128, clip=100, train_wall=54, wall=853\n","2021-05-15 13:26:15 | INFO | train_inner | epoch 001:   1400 / 20223 loss=6.133, nll_loss=4.09, ppl=17.03, wps=284.1, ups=1.83, wpb=155.6, bsz=2, num_updates=1400, lr=2.9973e-05, gnorm=10.724, clip=100, train_wall=54, wall=908\n","2021-05-15 13:27:10 | INFO | train_inner | epoch 001:   1500 / 20223 loss=6.107, nll_loss=4.062, ppl=16.7, wps=272.9, ups=1.83, wpb=149, bsz=2, num_updates=1500, lr=2.997e-05, gnorm=13.369, clip=100, train_wall=54, wall=963\n","2021-05-15 13:28:05 | INFO | train_inner | epoch 001:   1600 / 20223 loss=6.027, nll_loss=3.978, ppl=15.76, wps=274.3, ups=1.83, wpb=149.8, bsz=2, num_updates=1600, lr=2.9967e-05, gnorm=10.843, clip=100, train_wall=54, wall=1017\n","2021-05-15 13:28:59 | INFO | train_inner | epoch 001:   1700 / 20223 loss=6.046, nll_loss=4.009, ppl=16.1, wps=279.1, ups=1.83, wpb=152.8, bsz=2, num_updates=1700, lr=2.9964e-05, gnorm=10.274, clip=100, train_wall=54, wall=1072\n","2021-05-15 13:29:54 | INFO | train_inner | epoch 001:   1800 / 20223 loss=5.978, nll_loss=3.939, ppl=15.34, wps=286.1, ups=1.82, wpb=157.3, bsz=2, num_updates=1800, lr=2.9961e-05, gnorm=10.619, clip=100, train_wall=54, wall=1127\n","2021-05-15 13:30:49 | INFO | train_inner | epoch 001:   1900 / 20223 loss=5.878, nll_loss=3.838, ppl=14.3, wps=290, ups=1.83, wpb=158.9, bsz=2, num_updates=1900, lr=2.9958e-05, gnorm=10.333, clip=100, train_wall=54, wall=1182\n","2021-05-15 13:31:44 | INFO | train_inner | epoch 001:   2000 / 20223 loss=6.011, nll_loss=3.995, ppl=15.94, wps=284.6, ups=1.82, wpb=156.2, bsz=2, num_updates=2000, lr=2.9955e-05, gnorm=10.08, clip=100, train_wall=54, wall=1237\n","2021-05-15 13:32:39 | INFO | train_inner | epoch 001:   2100 / 20223 loss=5.945, nll_loss=3.925, ppl=15.19, wps=279.9, ups=1.83, wpb=152.9, bsz=2, num_updates=2100, lr=2.9952e-05, gnorm=10.418, clip=100, train_wall=54, wall=1291\n","2021-05-15 13:33:34 | INFO | train_inner | epoch 001:   2200 / 20223 loss=5.932, nll_loss=3.909, ppl=15.02, wps=286.6, ups=1.82, wpb=157.7, bsz=2, num_updates=2200, lr=2.9949e-05, gnorm=10.783, clip=100, train_wall=54, wall=1346\n","2021-05-15 13:34:28 | INFO | train_inner | epoch 001:   2300 / 20223 loss=5.859, nll_loss=3.833, ppl=14.25, wps=279.6, ups=1.83, wpb=152.8, bsz=2, num_updates=2300, lr=2.9946e-05, gnorm=9.582, clip=100, train_wall=54, wall=1401\n","2021-05-15 13:35:23 | INFO | train_inner | epoch 001:   2400 / 20223 loss=5.862, nll_loss=3.839, ppl=14.31, wps=274, ups=1.83, wpb=149.4, bsz=2, num_updates=2400, lr=2.9943e-05, gnorm=9.863, clip=100, train_wall=54, wall=1455\n","2021-05-15 13:36:18 | INFO | train_inner | epoch 001:   2500 / 20223 loss=5.823, nll_loss=3.803, ppl=13.95, wps=275.2, ups=1.83, wpb=150.6, bsz=2, num_updates=2500, lr=2.994e-05, gnorm=9.709, clip=100, train_wall=54, wall=1510\n","2021-05-15 13:37:12 | INFO | train_inner | epoch 001:   2600 / 20223 loss=5.796, nll_loss=3.77, ppl=13.64, wps=278.1, ups=1.83, wpb=152.2, bsz=2, num_updates=2600, lr=2.9937e-05, gnorm=10.097, clip=100, train_wall=54, wall=1565\n","2021-05-15 13:38:07 | INFO | train_inner | epoch 001:   2700 / 20223 loss=5.763, nll_loss=3.741, ppl=13.37, wps=282, ups=1.83, wpb=154.5, bsz=2, num_updates=2700, lr=2.9934e-05, gnorm=9.646, clip=100, train_wall=54, wall=1620\n","2021-05-15 13:39:02 | INFO | train_inner | epoch 001:   2800 / 20223 loss=5.713, nll_loss=3.689, ppl=12.9, wps=292.4, ups=1.81, wpb=161.1, bsz=2, num_updates=2800, lr=2.9931e-05, gnorm=9.323, clip=100, train_wall=54, wall=1675\n","2021-05-15 13:39:57 | INFO | train_inner | epoch 001:   2900 / 20223 loss=5.732, nll_loss=3.712, ppl=13.11, wps=276.2, ups=1.83, wpb=151.2, bsz=2, num_updates=2900, lr=2.9928e-05, gnorm=10, clip=100, train_wall=54, wall=1730\n","2021-05-15 13:40:52 | INFO | train_inner | epoch 001:   3000 / 20223 loss=5.807, nll_loss=3.8, ppl=13.93, wps=279, ups=1.83, wpb=152.8, bsz=2, num_updates=3000, lr=2.9925e-05, gnorm=12.81, clip=100, train_wall=54, wall=1784\n","2021-05-15 13:41:46 | INFO | train_inner | epoch 001:   3100 / 20223 loss=5.829, nll_loss=3.832, ppl=14.25, wps=283.1, ups=1.82, wpb=155.1, bsz=2, num_updates=3100, lr=2.9922e-05, gnorm=9.878, clip=100, train_wall=54, wall=1839\n","2021-05-15 13:42:41 | INFO | train_inner | epoch 001:   3200 / 20223 loss=5.681, nll_loss=3.66, ppl=12.64, wps=272.5, ups=1.83, wpb=148.7, bsz=2, num_updates=3200, lr=2.9919e-05, gnorm=11.405, clip=100, train_wall=54, wall=1894\n","2021-05-15 13:43:36 | INFO | train_inner | epoch 001:   3300 / 20223 loss=5.721, nll_loss=3.71, ppl=13.09, wps=283, ups=1.83, wpb=154.9, bsz=2, num_updates=3300, lr=2.9916e-05, gnorm=8.963, clip=100, train_wall=54, wall=1948\n","2021-05-15 13:44:31 | INFO | train_inner | epoch 001:   3400 / 20223 loss=5.665, nll_loss=3.646, ppl=12.52, wps=294.1, ups=1.81, wpb=162.5, bsz=2, num_updates=3400, lr=2.9913e-05, gnorm=8.887, clip=100, train_wall=54, wall=2004\n","2021-05-15 13:45:26 | INFO | train_inner | epoch 001:   3500 / 20223 loss=5.614, nll_loss=3.599, ppl=12.12, wps=282.2, ups=1.83, wpb=154.3, bsz=2, num_updates=3500, lr=2.991e-05, gnorm=9.619, clip=100, train_wall=54, wall=2058\n","2021-05-15 13:46:21 | INFO | train_inner | epoch 001:   3600 / 20223 loss=5.631, nll_loss=3.616, ppl=12.26, wps=289.3, ups=1.82, wpb=159.2, bsz=2, num_updates=3600, lr=2.9907e-05, gnorm=9.815, clip=100, train_wall=54, wall=2113\n","2021-05-15 13:47:16 | INFO | train_inner | epoch 001:   3700 / 20223 loss=5.692, nll_loss=3.688, ppl=12.88, wps=287.4, ups=1.82, wpb=157.6, bsz=2, num_updates=3700, lr=2.9904e-05, gnorm=8.98, clip=100, train_wall=54, wall=2168\n","2021-05-15 13:48:10 | INFO | train_inner | epoch 001:   3800 / 20223 loss=5.637, nll_loss=3.629, ppl=12.37, wps=270.9, ups=1.83, wpb=148.1, bsz=2, num_updates=3800, lr=2.9901e-05, gnorm=8.893, clip=100, train_wall=54, wall=2223\n","2021-05-15 13:49:05 | INFO | train_inner | epoch 001:   3900 / 20223 loss=5.574, nll_loss=3.557, ppl=11.77, wps=273.1, ups=1.84, wpb=148.7, bsz=2, num_updates=3900, lr=2.98979e-05, gnorm=9.953, clip=100, train_wall=54, wall=2277\n","2021-05-15 13:50:00 | INFO | train_inner | epoch 001:   4000 / 20223 loss=5.64, nll_loss=3.636, ppl=12.44, wps=294.7, ups=1.82, wpb=162.1, bsz=2, num_updates=4000, lr=2.98949e-05, gnorm=8.796, clip=100, train_wall=54, wall=2332\n","2021-05-15 13:50:54 | INFO | train_inner | epoch 001:   4100 / 20223 loss=5.552, nll_loss=3.538, ppl=11.62, wps=276.4, ups=1.83, wpb=150.7, bsz=2, num_updates=4100, lr=2.98919e-05, gnorm=8.645, clip=100, train_wall=54, wall=2387\n","2021-05-15 13:51:49 | INFO | train_inner | epoch 001:   4200 / 20223 loss=5.455, nll_loss=3.425, ppl=10.74, wps=266.3, ups=1.84, wpb=144.8, bsz=2, num_updates=4200, lr=2.98889e-05, gnorm=9.089, clip=100, train_wall=54, wall=2441\n","2021-05-15 13:52:43 | INFO | train_inner | epoch 001:   4300 / 20223 loss=5.62, nll_loss=3.616, ppl=12.26, wps=280.7, ups=1.83, wpb=153.5, bsz=2, num_updates=4300, lr=2.98859e-05, gnorm=8.631, clip=100, train_wall=54, wall=2496\n","2021-05-15 13:53:38 | INFO | train_inner | epoch 001:   4400 / 20223 loss=5.616, nll_loss=3.613, ppl=12.23, wps=281.3, ups=1.82, wpb=154.3, bsz=2, num_updates=4400, lr=2.98829e-05, gnorm=8.819, clip=100, train_wall=54, wall=2551\n","2021-05-15 13:54:33 | INFO | train_inner | epoch 001:   4500 / 20223 loss=5.559, nll_loss=3.549, ppl=11.71, wps=292.1, ups=1.82, wpb=160.6, bsz=2, num_updates=4500, lr=2.98799e-05, gnorm=9.336, clip=100, train_wall=54, wall=2606\n","2021-05-15 13:55:28 | INFO | train_inner | epoch 001:   4600 / 20223 loss=5.613, nll_loss=3.621, ppl=12.3, wps=285.6, ups=1.83, wpb=155.9, bsz=2, num_updates=4600, lr=2.98769e-05, gnorm=8.836, clip=100, train_wall=54, wall=2660\n","2021-05-15 13:56:23 | INFO | train_inner | epoch 001:   4700 / 20223 loss=5.52, nll_loss=3.506, ppl=11.36, wps=285.6, ups=1.82, wpb=156.7, bsz=2, num_updates=4700, lr=2.98739e-05, gnorm=8.985, clip=100, train_wall=54, wall=2715\n","2021-05-15 13:57:18 | INFO | train_inner | epoch 001:   4800 / 20223 loss=5.405, nll_loss=3.377, ppl=10.39, wps=279.3, ups=1.82, wpb=153.3, bsz=2, num_updates=4800, lr=2.98709e-05, gnorm=8.928, clip=100, train_wall=54, wall=2770\n","2021-05-15 13:58:12 | INFO | train_inner | epoch 001:   4900 / 20223 loss=5.443, nll_loss=3.419, ppl=10.7, wps=275.1, ups=1.83, wpb=150, bsz=2, num_updates=4900, lr=2.98679e-05, gnorm=8.814, clip=100, train_wall=54, wall=2825\n","2021-05-15 13:59:07 | INFO | train_inner | epoch 001:   5000 / 20223 loss=5.373, nll_loss=3.345, ppl=10.16, wps=283.5, ups=1.83, wpb=154.9, bsz=2, num_updates=5000, lr=2.98649e-05, gnorm=8.519, clip=100, train_wall=54, wall=2879\n","2021-05-15 14:04:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.135 | nll_loss 3.074 | ppl 8.42 | wps 1168 | wpb 76.6 | bsz 1 | num_updates 5000\n","^C\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zkot5FifZZKR"},"source":["# PREDICT"]},{"cell_type":"markdown","metadata":{"id":"KS7nVqMMRsuW"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":625},"id":"MK1BNmQXjfWg","executionInfo":{"status":"error","timestamp":1617568657095,"user_tz":-180,"elapsed":312958,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"8b12ee99-9a7b-4f43-9b03-f95870f4b929"},"source":["\n","from collections import namedtuple\n","\n","import torch\n","\n","from fairseq import checkpoint_utils, options, tasks, utils\n","\n","Batch = namedtuple('Batch', 'ids src_tokens src_lengths')\n","Translation = namedtuple('Translation', 'src_str hypos pos_scores alignments')\n","\n","def make_batches(lines, args, task, max_positions, encode_fn):\n","    tokens = [\n","        task.source_dictionary.encode_line(\n","            encode_fn(src_str), add_if_not_exist=False\n","        ).long()\n","        for src_str in lines\n","    ]\n","    lengths = torch.LongTensor([t.numel() for t in tokens])\n","    itr = task.get_batch_iterator(\n","        dataset=task.build_dataset_for_inference(tokens, lengths),\n","        max_tokens=args.max_tokens,\n","        max_sentences=args.max_sentences,\n","        max_positions=max_positions,\n","    ).next_epoch_itr(shuffle=False)\n","    for batch in itr:\n","        yield Batch(\n","            ids=batch['id'],\n","            src_tokens=batch['net_input']['src_tokens'], src_lengths=batch['net_input']['src_lengths'],\n","        )\n","\n","class Generator():\n","    def __init__(self, data_path, checkpoint_path=\"checkpoint_best.pt\"):\n","        self.parser = options.get_generation_parser(interactive=True)\n","        self.parser.set_defaults(path=checkpoint_path,\n","            remove_bpe=\"sentencepiece\", dataset_impl=\"lazy\", num_wokers=5\n","        )\n","        self.args = options.parse_args_and_arch(self.parser, \n","            input_args=[data_path]\n","        )\n","\n","        utils.import_user_module(self.args)\n","\n","        if self.args.buffer_size < 1:\n","            self.args.buffer_size = 1\n","        #if self.args.max_tokens is None and self.args.max_sentences is None:\n","        #    self.args.max_sentences = 1\n","\n","       # assert not self.args.sampling or self.args.nbest == self.args.beam, \\\n","       #     '--sampling requires --nbest to be equal to --beam'\n","       # assert not self.args.max_sentences or self.args.max_sentences <= self.args.buffer_size, \\\n","        #    '--max-sentences/--batch-size cannot be larger than --buffer-size'\n","\n","        self.use_cuda = torch.cuda.is_available() and not self.args.cpu\n","\n","        self.task = tasks.setup_task(self.args)\n","\n","        self.models, self._model_args = checkpoint_utils.load_model_ensemble(\n","            self.args.path.split(':'),\n","            arg_overrides=eval(self.args.model_overrides),\n","            task=self.task,\n","        )\n","\n","        self.src_dict = self.task.source_dictionary\n","        self.tgt_dict = self.task.target_dictionary\n","\n","        for model in self.models:\n","            model.make_generation_fast_(\n","                beamable_mm_beam_size=None if self.args.no_beamable_mm else self.args.beam,\n","                need_attn=self.args.print_alignment,\n","            )\n","            if self.args.fp16:\n","                model.half()\n","            if self.use_cuda:\n","                model.cuda()\n","\n","        self.generator = self.task.build_generator(self.args)\n","\n","        if self.args.remove_bpe == 'gpt2':\n","            from fairseq.gpt2_bpe.gpt2_encoding import get_encoder\n","            self.decoder = get_encoder(\n","                'fairseq/gpt2_bpe/encoder.json',\n","                'fairseq/gpt2_bpe/vocab.bpe',\n","            )\n","            self.encode_fn = lambda x: ' '.join(map(str, self.decoder.encode(x)))\n","        else:\n","            self.decoder = None\n","            self.encode_fn = lambda x: x\n","\n","        self.align_dict = utils.load_align_dict(self.args.replace_unk)\n","\n","        self.max_positions = utils.resolve_max_positions(\n","            self.task.max_positions(),\n","            *[model.max_positions() for model in self.models]\n","        )\n","\n","    def generate(self, string):\n","        start_id = 0\n","        inputs = [string]\n","        results = []\n","        for batch in make_batches(inputs, self.args, self.task, self.max_positions, self.encode_fn):\n","            src_tokens = batch.src_tokens\n","            src_lengths = batch.src_lengths\n","            if self.use_cuda:\n","                src_tokens = src_tokens.cuda()\n","                src_lengths = src_lengths.cuda()\n","\n","            sample = {\n","                'net_input': {\n","                    'src_tokens': src_tokens,\n","                    'src_lengths': src_lengths,\n","                },\n","            }\n","            translations = self.task.inference_step(self.generator, self.models, sample)\n","            for i, (id, hypos) in enumerate(zip(batch.ids.tolist(), translations)):\n","                src_tokens_i = utils.strip_pad(src_tokens[i], self.tgt_dict.pad())\n","                results.append((start_id + id, src_tokens_i, hypos))\n","\n","        for id, src_tokens, hypos in sorted(results, key=lambda x: x[0]):\n","            if self.src_dict is not None:\n","                src_str = self.src_dict.string(src_tokens, self.args.remove_bpe)\n","\n","            for hypo in hypos[:min(len(hypos), self.args.nbest)]:\n","                hypo_tokens, hypo_str, alignment = utils.post_process_prediction(\n","                    hypo_tokens=hypo['tokens'].int().cpu(),\n","                    src_str=src_str,\n","                    alignment=hypo['alignment'].int().cpu() if hypo['alignment'] is not None else None,\n","                    align_dict=self.align_dict,\n","                    tgt_dict=self.tgt_dict,\n","                    remove_bpe=self.args.remove_bpe,\n","                )\n","                if self.decoder is not None:\n","                    hypo_str = self.decoder.decode(map(int, hypo_str.strip().split()))\n","\n","                return hypo_str\n","\n","if __name__ == '__main__':\n","    gen = Generator(\"/content/drive/MyDrive/postprocessed/-bin\", \"/content/drive/MyDrive/checkpoint/small_train/checkpoint_best.pt\")\n","\n","    #print(gen.generate(\"Koronavirusai yra virusai, kurie cirkuliuoja tarp gyvūnų, tačiau žinoma, kad kai kurie iš jų sukelia infekcijas žmonėms. Sukėlę infekciją žmonėms, jie toliau gali būti perduoti nuo žmogaus žmogui. Koronavirusų infekcijos šaltinis gali būti daugybė gyvūnų. Pavyzdžiui, Artimųjų Rytų respiracinio sindromo koronaviruso (MERS-CoV) šaltinis buvo kupranugariai, o sunkaus ūmaus respiracinio sindromo (SŪRS) - civetės katės. Šis naujas Kinijoje aptiktas koronavirusas yra genetiškai glaudžiai panašus į SŪRS sukeliantį virusą. SŪRS atsirado 2002 m. pabaigoje Kinijoje ir per aštuonis mėnesius 33 šalys pranešė apie daugiau nei 8 000 SŪRS atvejų. Tuo metu nuo šio viruso mirė kas dešimtas susirgęs asmuo. Šiuo metu yra per mažai duomenų, kad būtų galima vertinti mirštamumą nuo COVID-19, tačiau preliminarūs duomenys rodo, kad jis yra mažesnis, nei nuo SŪRS. Nors gripo ir COVID-19 perdavimo keliai ir simptomai yra panašūs, šias infekcijas sukeliantys virusai yra labai skirtingi. Dar labai anksti daryti išvadas, kaip plinta naujasis koronavirusas, tačiau išankstinė informacija rodo, kad jo plitimo mechanizmas yra labiau panašus į SŪRS ar pandeminio gripo, negu į sezoninio gripo plitimo mechanizmą, nes žmonės niekada prieš tai nebuvo susidūrę šia infekcija. Europos ligų prevencijos ir kontrolės centro (ECDC) duomenimis, Europoje nuo gripo ir jo sukeltų komplikacijų kasmet miršta apie 40 000 žmonių. Dabartiniai tyrimai sieja COVID-19 su tam tikrais šikšnosparnių tipais, tačiau neatmetama galimybė, kad infekcijos šaltinis galėjo būti ir kiti gyvūnai. Nėra įrodymų, kad tokie naminiai gyvūnai kaip šunys ar katės gali tapti naujojo koronaviruso šaltiniu, tačiau kontaktuojant su gyvūnais rekomenduojama laikytis bendrų higienos principų.\"))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-e9e2f8a71f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/postprocessed/-bin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/checkpoint/small_train/checkpoint_best.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m#print(gen.generate(\"Koronavirusai yra virusai, kurie cirkuliuoja tarp gyvūnų, tačiau žinoma, kad kai kurie iš jų sukelia infekcijas žmonėms. Sukėlę infekciją žmonėms, jie toliau gali būti perduoti nuo žmogaus žmogui. Koronavirusų infekcijos šaltinis gali būti daugybė gyvūnų. Pavyzdžiui, Artimųjų Rytų respiracinio sindromo koronaviruso (MERS-CoV) šaltinis buvo kupranugariai, o sunkaus ūmaus respiracinio sindromo (SŪRS) - civetės katės. Šis naujas Kinijoje aptiktas koronavirusas yra genetiškai glaudžiai panašus į SŪRS sukeliantį virusą. SŪRS atsirado 2002 m. pabaigoje Kinijoje ir per aštuonis mėnesius 33 šalys pranešė apie daugiau nei 8 000 SŪRS atvejų. Tuo metu nuo šio viruso mirė kas dešimtas susirgęs asmuo. Šiuo metu yra per mažai duomenų, kad būtų galima vertinti mirštamumą nuo COVID-19, tačiau preliminarūs duomenys rodo, kad jis yra mažesnis, nei nuo SŪRS. Nors gripo ir COVID-19 perdavimo keliai ir simptomai yra panašūs, šias infekcijas sukeliantys virusai yra labai skirtingi. Dar labai anksti daryti išvadas, kaip plinta naujasis koronavirusas, tačiau išankstinė informacija rodo, kad jo plitimo mechanizmas yra labiau panašus į SŪRS ar pandeminio gripo, negu į sezoninio gripo plitimo mechanizmą, nes žmonės niekada prieš tai nebuvo susidūrę šia infekcija. Europos ligų prevencijos ir kontrolės centro (ECDC) duomenimis, Europoje nuo gripo ir jo sukeltų komplikacijų kasmet miršta apie 40 000 žmonių. Dabartiniai tyrimai sieja COVID-19 su tam tik...\n","\u001b[0;32m<ipython-input-14-e9e2f8a71f97>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path, checkpoint_path)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0marg_overrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_overrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fairseq/checkpoint_utils.py\u001b[0m in \u001b[0;36mload_model_ensemble\u001b[0;34m(filenames, arg_overrides, task, strict, suffix, num_shards)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mnum_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fairseq/checkpoint_utils.py\u001b[0m in \u001b[0;36mload_model_ensemble_and_task\u001b[0;34m(filenames, arg_overrides, task, strict, suffix, num_shards)\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;31m# build model for ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fairseq/models/fairseq_model.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, args)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupgrade_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mnew_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupgrade_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1224\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BARTModel:\n\tsize mismatch for encoder.embed_tokens.weight: copying a param with shape torch.Size([250027, 1024]) from checkpoint, the shape in current model is torch.Size([250001, 1024]).\n\tsize mismatch for decoder.embed_tokens.weight: copying a param with shape torch.Size([250027, 1024]) from checkpoint, the shape in current model is torch.Size([250001, 1024]).\n\tsize mismatch for decoder.output_projection.weight: copying a param with shape torch.Size([250027, 1024]) from checkpoint, the shape in current model is torch.Size([250001, 1024])."]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_ybMNepROnd","executionInfo":{"status":"ok","timestamp":1617567467685,"user_tz":-180,"elapsed":1812,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"7ad140a2-01fc-438a-fcbc-cbc72dae4998"},"source":["MODEL_DIR = \"/content/drive/MyDrive/checkpoint/small_train\"\n","!python /fairseq/fairseq_cli/interactive.py /content/drive/MyDrive/postprocessed/-bin \\\n","    --source-lang en_XX --target-lang lt_LT \\\n","    --input /content/drive/MyDrive/evaluation.txt $MODEL_DIR \\\n","    --path $MODEL_DIR/checkpoint_best.pt \\\n","    --batch-size 1 --beam 5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["usage: interactive.py [-h] [--no-progress-bar] [--log-interval N]\n","                      [--log-format {json,none,simple,tqdm}]\n","                      [--tensorboard-logdir DIR] [--seed N] [--cpu] [--fp16]\n","                      [--memory-efficient-fp16] [--fp16-no-flatten-grads]\n","                      [--fp16-init-scale FP16_INIT_SCALE]\n","                      [--fp16-scale-window FP16_SCALE_WINDOW]\n","                      [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]\n","                      [--min-loss-scale D]\n","                      [--threshold-loss-scale THRESHOLD_LOSS_SCALE]\n","                      [--user-dir USER_DIR]\n","                      [--empty-cache-freq EMPTY_CACHE_FREQ]\n","                      [--all-gather-list-size ALL_GATHER_LIST_SIZE]\n","                      [--model-parallel-size N]\n","                      [--checkpoint-suffix CHECKPOINT_SUFFIX]\n","                      [--quantization-config-path QUANTIZATION_CONFIG_PATH]\n","                      [--criterion {sentence_ranking,sentence_prediction,composite_loss,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,binary_cross_entropy,masked_lm,nat_loss,adaptive_loss,cross_entropy,legacy_masked_lm_loss,vocab_parallel_cross_entropy}]\n","                      [--tokenizer {moses,space,nltk}]\n","                      [--bpe {byte_bpe,bytes,subword_nmt,fastbpe,hf_byte_bpe,characters,sentencepiece,gpt2,bert}]\n","                      [--optimizer {nag,lamb,adadelta,adamax,adafactor,adagrad,sgd,adam}]\n","                      [--lr-scheduler {tri_stage,cosine,inverse_sqrt,reduce_lr_on_plateau,triangular,fixed,polynomial_decay}]\n","                      [--task TASK] [--num-workers N]\n","                      [--skip-invalid-size-inputs-valid-test] [--max-tokens N]\n","                      [--max-sentences N] [--required-batch-size-multiple N]\n","                      [--dataset-impl FORMAT] [--data-buffer-size N]\n","                      [--gen-subset SPLIT] [--num-shards N] [--shard-id ID]\n","                      [--path FILE] [--remove-bpe [REMOVE_BPE]] [--quiet]\n","                      [--model-overrides DICT] [--results-path RESDIR]\n","                      [--beam N] [--nbest N] [--max-len-a N] [--max-len-b N]\n","                      [--min-len N] [--match-source-len] [--no-early-stop]\n","                      [--unnormalized] [--no-beamable-mm] [--lenpen LENPEN]\n","                      [--unkpen UNKPEN] [--replace-unk [REPLACE_UNK]]\n","                      [--sacrebleu] [--score-reference] [--prefix-size PS]\n","                      [--no-repeat-ngram-size N] [--sampling]\n","                      [--sampling-topk PS] [--sampling-topp PS]\n","                      [--temperature N] [--diverse-beam-groups N]\n","                      [--diverse-beam-strength N] [--diversity-rate N]\n","                      [--print-alignment] [--print-step]\n","                      [--iter-decode-eos-penalty N] [--iter-decode-max-iter N]\n","                      [--iter-decode-force-max-iter]\n","                      [--iter-decode-with-beam N]\n","                      [--iter-decode-with-external-reranker]\n","                      [--retain-iter-history]\n","                      [--decoding-format {unigram,ensemble,vote,dp,bs}]\n","                      [--buffer-size N] [--input FILE] [--momentum M]\n","                      [--weight-decay WD] [--force-anneal N] [--lr-shrink LS]\n","                      [--warmup-updates N] [-s SRC] [-t TARGET]\n","                      [--load-alignments] [--left-pad-source BOOL]\n","                      [--left-pad-target BOOL] [--max-source-positions N]\n","                      [--max-target-positions N]\n","                      [--upsample-primary UPSAMPLE_PRIMARY]\n","                      [--truncate-source] [--eval-bleu]\n","                      [--eval-bleu-detok EVAL_BLEU_DETOK]\n","                      [--eval-bleu-detok-args JSON] [--eval-tokenized-bleu]\n","                      [--eval-bleu-remove-bpe [EVAL_BLEU_REMOVE_BPE]]\n","                      [--eval-bleu-args JSON] [--eval-bleu-print-samples]\n","                      data\n","interactive.py: error: unrecognized arguments: /content/drive/MyDrive/checkpoint/small_train\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j60MA5GL0OHN"},"source":["\n","# CHECKPOINT_PATH=\"/content/drive/MyDrive/checkpoint/checkpoint_last.pt\" \n","# DATA_BIN_PATH=\"/content/drive/MyDrive/postprocessed/-bin/\"\n","# #SENTENCE_BPE_MODEL=\"/content/mbart.cc25/sentence.bpe.model\"\n","# DATADIR = \"/content/drive/MyDrive/postprocessed/-bin/\"\n","# #OUTPUT_FILE=\"/content/drive/MyDrive/vgtu/checkpoint/\"\n","\n","# !python /fairseq/generate.py \\\n","#   $DATADIR \\\n","#   --path \"$CHECKPOINT_PATH\" \\\n","#   --task translation_from_pretrained_bart \\\n","#   --gen-subset test -t en_XX -s lt_LT \\\n","#   --batch-size 2 \\\n","#   --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN \\\n","#   --bpe \"sentencepiece\" \\\n","#   --sentencepiece-vocab \"/content/mbart.cc25\";\n","#   #--scoring sacrebleu > \"/content/drive/MyDrive/vgtu/checkpoint/tst.txt\";"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zl3y-vZsX5Dz"},"source":["# model_dir=\"/content/drive/MyDrive/checkpoint/\" # fix if you moved the checkpoint\n","# langs=ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN\n","# fairseq-generate \"/content/drive/MyDrive/postprocessed/-bin/\" \\\n","#   --path $model_dir/checkpoint_best.pt \\\n","#   --task translation_from_pretrained_bart \\\n","#   --gen-subset test \\\n","#   -t lt_LT -s en_XX \\\n","#   --bpe 'sentencepiece' --sentencepiece-model \"/content/drive/MyDrive/checkpoint/sentence.bpe.model\" \\\n","#   --sacrebleu --remove-bpe 'sentencepiece' \\\n","#   --batch-size 32 --langs $langs > lt_LT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":837},"id":"GVpipbSHTSLj","executionInfo":{"status":"ok","timestamp":1617568012473,"user_tz":-180,"elapsed":6348,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"b6a5b0ed-32ca-45d8-b18c-8abae8a7cf8f"},"source":["!pip install fairseq"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting fairseq\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/ab/92c6efb05ffdfe16fbdc9e463229d9af8c3b74dc943ed4b4857a87b223c2/fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7MB)\n","\u001b[K     |████████████████████████████████| 1.7MB 7.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.19.5)\n","Collecting dataclasses\n","  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.41.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.22)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.8.1+cu101)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2019.12.20)\n","Collecting hydra-core\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 34.2MB/s \n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.14.5)\n","Collecting sacrebleu>=1.4.12\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq) (3.7.4.3)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.1.2)\n","Collecting antlr4-python3-runtime==4.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n","\u001b[K     |████████████████████████████████| 112kB 33.2MB/s \n","\u001b[?25hCollecting omegaconf<2.1,>=2.0.5\n","  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.20)\n","Collecting portalocker==2.0.0\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core->fairseq) (3.4.1)\n","Collecting PyYAML>=5.1.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 33.6MB/s \n","\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=840f7ef0376f6c2b180df52026c8c371c0c6bb02f477a73097eed5eb9e06ba2a\n","  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: dataclasses, antlr4-python3-runtime, PyYAML, omegaconf, hydra-core, portalocker, sacrebleu, fairseq\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.0.6 omegaconf-2.0.6 portalocker-2.0.0 sacrebleu-1.5.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dataclasses"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"BGRbF2BKTVHv"},"source":["from fairseq.models.bart import BARTModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lcRKK6NkTYbx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617529197373,"user_tz":-180,"elapsed":310254,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"efda4e5b-bf0e-4a56-c141-44001f4afda6"},"source":["# VEIKIANTIS\n","# https://tmramalho.github.io/science/2020/06/10/fine-tune-neural-translation-models-with-mBART/\n","#from fairseq.models.bart import BARTModel\n","\n","BASEDIR = '/content/drive/MyDrive/checkpoint/small_train'\n","bart = BARTModel.from_pretrained(\n","        BASEDIR,\n","        checkpoint_file='checkpoint_best.pt',\n","        bpe='sentencepiece',\n","        sentencepiece_model=f'{BASEDIR}/sentence.bpe.model')\n","bart.eval() #for evaluation\n","#bart.train() to resume training\n","\n","#sentence_list = ['旅行に来る外国人はこれからも少ないままになりそうです。このため、日本の経済はとても厳しくなっています。']\n","#translation = bart.sample(sentence_list, beam=5)\n","#print(translation)\n","#breakpoint()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BARTHubInterface(\n","  (model): BARTModel(\n","    (encoder): TransformerEncoder(\n","      (dropout_module): FairseqDropout()\n","      (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n","      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n","      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (layers): ModuleList(\n","        (0): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (6): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (7): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (8): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (9): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (10): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (11): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): TransformerDecoder(\n","      (dropout_module): FairseqDropout()\n","      (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n","      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n","      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (layers): ModuleList(\n","        (0): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (6): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (7): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (8): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (9): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (10): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (11): TransformerDecoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_dropout_module): FairseqDropout()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (output_projection): Linear(in_features=1024, out_features=250027, bias=False)\n","    )\n","    (classification_heads): ModuleDict()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"7k7j8upVgCrd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617283391724,"user_tz":-180,"elapsed":139641,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"7b46edf9-c4e0-4a4c-8cd0-4a6f2b4cba9c"},"source":["# # mbart treniruotas mazu kiekiu tekstu (~1k)\n","\n","# a = [\"Kaip pranešė Policijos departamentas, parlamentaras į policiją kreipėsi apie devintą ryto ir nurodė, kad grasinantį laišką į darbinį elektroninį paštą jis gavo apie penktą valandą ryto. Sostinės policijos atstovė Julija Samorokovskaja BNS sakė, kad E. Sabutis savo pareiškime nurodė, jog laiške grasinama su juo susidoroti dėl to, kad jis yra Seimo narys. Siuntėjo parlamentaras sakė nepažįstantis. Policija pradėjo ikiteisminį tyrimą dėl grasinimo nužudyti ar sunkiai sutrikdyti sveikatą. Laiške prašoma socialinio būsto Laiške, kurį gavo keli parlamentarai rašoma, kad jei asmuo negaus socialinio būsto, „ateisiu pas jus ir subadysiu kaip šunis“. Pateikiame visą laiško tekstą, kalba netaisyta. „Labas Jai jus man neduosite socelinio būso aš ateisiu pas jus ir ir subadisiu kaip šunis galėsite pamatiti daug negyvų žmonių kūnų. Jai duodate sirijos ir Baltarusijos piliečiams kur gyventi tai atsakisite vietos ir man. Kiek aš dar laiko gyvensiu kaip šuva ant gatvės“.\"]\n","# b = [\"Dėsnis teigia, kad tam tikromis sąlygomis atsitiktinių veiksnių visuma ilgainiui nulemia rezultatą, nepriklausantį arba mažai priklausantį nuo atsitiktinumo. Tikimybių teorijoje ir matematinėje statistikoje didžiųjų skaičių dėsnis teigia, kad vienodomis sąlygomis daug kartų stebint tą patį atsitiktinį dydį stebėtų reikšmių aritmetinis vidurkis artėja prie tam tikros neatsitiktinės reikšmės, vadinamos stebimojo dydžio (teoriniu) vidurkiu. Kai vienodomis sąlygomis ilgą laiką stebimas tas pats įvykis, kurio pasirodymo tikimybė yra p, didžiųjų skaičių dėsnis teigia, kad to įvykio pasirodymų santykinis dažnis artėja prie p. Pvz., neribotai metant simetrišką monetą santykinis herbo atvirtimų dažnis artėja prie teorinės tokio atvirtimo tikimybės, lygios . Vienas didžiųjų skaičių dėsnio matematinių tikslių formulavimų yra toks: jei X1, X2, …, Xn, …, yra nepriklausomųjų vienodai pasiskirsčiusių atsitiktinių dydžių su vidurkiais EXn = a seka, tai aritmetinis vidurkis (X1 + X2 + ... + Xn)/n artėja prie a, kai n neribotai auga. Pagal artėjimo pobūdį (su tikimybe 1 arba pagal tikimybę) skiriama stiprusis arba silpnasis didžiųjų skaičių dėsnis. Dėsnio apibendrinimai nagrinėja atvejus, kai atsitiktiniai dydžiai nėra vienodai pasiskirstę arba nėra nepriklausomi. Nepriklausomųjų atsitiktinių dydžių sumų ribinę elgseną tiksliau aprašo centrinė ribinė teorema. Atskirą didžiųjų skaičių dėsnio atvejį suformulavo ir 1713 paskelbė J. Bernoullis. 1837 apibendrino ir didžiųjų skaičių dėsnio terminą pirmasis pavartojo S. D. Poissonas. 1867 didžiųjų skaičių dėsnio sąvoką praplėtė P. Čebyšovas.\"]\n","# c = [\"Iki šiol kelionės traukiniais buvo landa, kuria žmonės bandydavo apeiti judėjimo ribojimus, nes griežta kontrolė čia netaikyta. Tačiau Velykų savaitgalį šansų prasmukti be patikros nebeliks, o kontrolė pradėta jau ketvirtadienį. „Šiandien mes patikrinsime keleivius vykstančius traukiniu, kalbinsime juos apie buvimą Vilniuje, kokiomis aplinkybėmis jie atsirado Vilniuje, kur jie ruošiasi važiuoti, kalbinsime ir informuosime juos apie Vyriausybės nutarimo reikalavimus dėl karantino laikymosi ir informuosime apie atsakomybę už to nutarimo sąlygų nesilaikymo“, – kalbėjo Vilniaus miesto trečiojo policijos komisariato viršininkas Donaldas Dubaka. Ketvirtadienio popietę į Kauną vykstantį traukinį lipo kelios dešimtys keleivių. Dauguma jų Kauno gyventojai, atvykę į Vilnių darbo ar medicininiais reikalais. Tiesa, vienas patikrintas jaunuolis negalėjo įtikinamai paaiškinti, kodėl lankėsi Vilniuje. „Susitikti su giminaičiu atvažiavau, tiesiog pasikalbėti – pareigūnui aiškino jaunuolis ir pridūrė. – Tai čia savaitgalį turėtų būti ribojimai, savaitgalį tik griežtesni ribojimai.“ Tačiau jis buvo informuotas, kad karantinas galioja visą laiką. Policininkas užsirašė vaikino duomenis ir įspėjo, kad dabar bus atliekamas tyrimas, o jam gresia bauda, nes be rimtos priežasties atvyko į sostinę ir pažeidė judėjimo ribojimus.\"]\n","# d = [\"Koronavirusai yra virusai, kurie cirkuliuoja tarp gyvūnų, tačiau žinoma, kad kai kurie iš jų sukelia infekcijas žmonėms. Sukėlę infekciją žmonėms, jie toliau gali būti perduoti nuo žmogaus žmogui. Koronavirusų infekcijos šaltinis gali būti daugybė gyvūnų. Pavyzdžiui, Artimųjų Rytų respiracinio sindromo koronaviruso (MERS-CoV) šaltinis buvo kupranugariai, o sunkaus ūmaus respiracinio sindromo (SŪRS) - civetės katės. Šis naujas Kinijoje aptiktas koronavirusas yra genetiškai glaudžiai panašus į SŪRS sukeliantį virusą. SŪRS atsirado 2002 m. pabaigoje Kinijoje ir per aštuonis mėnesius 33 šalys pranešė apie daugiau nei 8 000 SŪRS atvejų. Tuo metu nuo šio viruso mirė kas dešimtas susirgęs asmuo. Šiuo metu yra per mažai duomenų, kad būtų galima vertinti mirštamumą nuo COVID-19, tačiau preliminarūs duomenys rodo, kad jis yra mažesnis, nei nuo SŪRS. Nors gripo ir COVID-19 perdavimo keliai ir simptomai yra panašūs, šias infekcijas sukeliantys virusai yra labai skirtingi. Dar labai anksti daryti išvadas, kaip plinta naujasis koronavirusas, tačiau išankstinė informacija rodo, kad jo plitimo mechanizmas yra labiau panašus į SŪRS ar pandeminio gripo, negu į sezoninio gripo plitimo mechanizmą, nes žmonės niekada prieš tai nebuvo susidūrę šia infekcija. Europos ligų prevencijos ir kontrolės centro (ECDC) duomenimis, Europoje nuo gripo ir jo sukeltų komplikacijų kasmet miršta apie 40 000 žmonių. Dabartiniai tyrimai sieja COVID-19 su tam tikrais šikšnosparnių tipais, tačiau neatmetama galimybė, kad infekcijos šaltinis galėjo būti ir kiti gyvūnai. Nėra įrodymų, kad tokie naminiai gyvūnai kaip šunys ar katės gali tapti naujojo koronaviruso šaltiniu, tačiau kontaktuojant su gyvūnais rekomenduojama laikytis bendrų higienos principų. \"]\n","# e = [\"Burlenčių sportas (kartais vadinamas tiesiog buriavimu) – ekstremalus vandens sportas ir pramoga, kurios pagrindas yra judėjimas vandens paviršiumi panaudojant specialią įrangą, vadinamą burlente. Burlentė yra 2–4 m ilgio plūdrios medžiagos lenta, sujungta su viena bure per lanksčią jungtį. Burlenčių sportas yra buriavimo ir banglenčių sporto hibridas. Burlentė – supaprastintas burinio laivo modelis, kuris vairuojamas palenkiant burę pirmyn arba atgal. Buriuoti burlentėmis galima tiek lygiame vandenyje, tiek bangų mūšoje. Buriavimas burlentėmis yra labai universalus sportas – vieniems tai smagus poilsis prie vandens, kitiems įtemptas lenktyniavimas, dar kitiems – gyvenimo stilius, kurio esmė – tobulos bangos paieškos. Buriavimui reikia ne tiek fizinės jėgos, kiek vikrumo ir lygsvaros. Buriuoti burlentėmis galima esant vėjo greičiui nuo 3 iki 20 m/s, tačiau geriausia, kai vėjo greitis yra tarp 5 ir 15 m/s.\"]\n","# f = [\"automobilių sporto lenktynės, organizuojamos Tarptautinės Automobilininkų Federacijos FIA (pranc. Fédération Internationale de l'Automobile) ir laikomos automobilių sporto viršūne. Oficialus pavadinimas – FIA Formulės Vienas Pasaulio Čempionatas (angl. FIA Formula One World Championship). Tai – brangiausia sporto šaka pasaulyje, savo istoriją skaičiuojanti nuo 1950-ųjų. Pirmuoju asmeninės įskaitos čempionu tapo italas Giuseppe Farina, o pirmoji komanda, iškovojusi konstruktorių taurę (įsteigtą 1958 m.) – Vanwall ekipa. Sėkmingiausias F1 pilotas, kuriam priklauso beveik visi rekordai – vokietis Michaelis Schumacheris, tarp ekipų išsiskiria italų Ferrari (tai vienintelė komanda, lenktyniaujanti nuo pat pirmojo 1950-ųjų m. sezono) komanda.\"]\n","# g = [\"Bet meskim visus išvedžiojimus ir eikim tiesiai prie įspūdingų skaičių. Išbandytas ir užgrūdintas 8 litrų variklis generuoja 1578 arklio galias (1177 kW), kaip galėjome įsitikinti, skriedami „Centodieci“ arba „Super Sport 300+“ modeliais. Tačiau „Bugatti“ ties tuo nesustojo ir perkonstravo šį variklį taip, kad jį būtų galima „maitinti“ lenktyniniais degalais, kurių oktaninis skaičius siekia 110. Šis patobulinimas leido pasiekti stulbinamas 1825 AG (1361 kW), esant 7 tūkst. aps./min. ir 1850 niutonmetrų sukimo momentą, esant 2 tūkst. aps./min. Galios šuolis taip pat buvo pasiektas sukūrus naujus keturgubus turbokompresorius.Taikydami įvairias svorio taupymo priemones, inžinieriai iš Molsheimo sugebėjo sumažinti „Bolide“ svorį iki 1240 kilogramų arba maždaug tiek, kiek sveria įprastas europietiškas kompaktiškas automobilis.Nenuostabu, kad toks galingas ir tiek nedaug sveriantis lenktyninis hiperautomobilis yra tikra raketa. Nuo 0 iki 100 km/val. jis įsibėgi vos per 2,17 sekundes, o 200 km/val. greitį pasiekia per 4,36 sekundes. Bet nepamirškite, kad kol kas „Bugatti“ neatliko šių pagreičio testų realiomis sąlygomis – visa tai tėra simuliacijose gauti rezultatai. Tas pats pasakytina ir apie įsibėgėjimą nuo 0 iki 300 km/val. per 7,37 sekundes bei iki 400 km/val. per 12,08 sekundes.„Bugatti“ netgi pateikė teorinį įsibėgėjimo nuo 0 iki 500 km/val. laiką, kuris siekia 20,16 sekundes. Kitaip tariant, „Bolide“ Niurnburgringo trasą turėtų įveikti per 5 minutes ir 23,1 sekundes. Maksimalus greitis? „Gerokai virš 500 km/val.“, o „Le Mano“ rato įveikimo laikas užfiksuotas ties 3 minutėmis ir 7,1 sekundėmis. Vėlgi visa tai tėra simuliacijų rodikliai.Nevertėtų pamiršti ir dizaino. Tik pažiūrėkite į jį. Jei manėte, kad „Bugatti Vision Gran Turismo“ yra iš kito pasaulio, tai „Bolide“ neabejotinai atskriejęs iš tolimos galaktikos. Iš tikrųjų čia slypi kur kas daugiau dalykų, nei galima įžiūrėti plika akimi. Naujasis automobilis gali pasigirti „transformuojama oda“ (kaip „Bugatti“ tai vadina), kurios tikslas – pagerinti oro patekimą į ant stogo esantį ėmiklį. Važiuojant lėtai, ėmiklio paviršius išlieka lygus, tačiau kiek stipriau spustelėjus akceleratorių, jis išsiplečia.Oficialios automobilio nuotraukos ne visiškai tiksliai atspindi jo prošvaisą, kuri siekia vos 995 mm ir yra maždaug 300 mm mažesnė nei įprastas „Chiron“ aukštis. Dėl X formos priekinių ir galinių žibintų „Bolide“ atrodo kaip ką tik išriedėjęs iš mokslinės fantastikos filmo.Vos per 9 mėnesius sukurtas „Bolide“ kol kas nėra įvertintas pinigine išraiška. Taip yra dėl to, kad „Bugatti“ vis dar svarsto, ar verta pradėti šio „aukščiausios klasės vidaus degimo variklio“ gamybą.\"]\n","\n","\n","# lst = [a,b,c,d,e,f, g]\n","# summ = []\n","# for i,txt in enumerate(lst):\n","#   print(i)\n","#   translation = bart.sample(\n","#     txt, \n","#     beam=5, \n","#     no_repeat_ngram_size=2,  \n","#     early_stopping=True)\n","#   #translation = bart.sample(txt, beam=5, no_repeat_ngram_size=3, do_sample=True)\n","#   print(translation)\n","  \n","#   summ.append(translation)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","['Parlamentaras Egidijus Sabutis, kuris grasina nužudyti ar sunkiai sutrikdyti sveikatą, prašo socialinio būsto, pranešė policija.[lt_LT]']\n","1\n","['Didžiųjų skaičių dėsnis teigia, kad tam tikromis sąlygomis atsitiktinių veiksnių visuma ilgainiui nulemia rezultatą, nepriklausantį arba mažai priklausančią nuo atsititiktinumo.[lt_LT]']\n","2\n","['Vilniaus miesto trečiojo policijos komisariato viršininkas Donaldas Dubaka ketvirtadienio popietę patikrino į Kauną vykstantį traukinį ir įspėjo, kad dėl karantino laikymosi bus griežta kontrolė.[lt_LT]']\n","3\n","['Koronavirusai yra virusai, kurie cirkuliuoja tarp gyvūnų, tačiau žinoma, kad kai kurie iš jų sukelia infekcijas žmonėms, jie toliau gali būti perduoti nuo žmogaus žmogui.[lt_LT]']\n","4\n","['Burlenčių sportas (kartais vadinamas tiesiog buriavimu) – ekstremalus vandens sportos ir pramoga, kurios pagrindas yra judėjimas vandens paviršiumi panaudojant specialią įrangą, vadinamą burlente. Burlentė yra 2–4 m ilgio plūdrios medžiagos lenta, sujungta su viena bure per lanksčią jungtį.[lt_LT]']\n","5\n","[\"automobilių sporto lenktynės, organizuojamos Tarptautinės Automobilininkų Federacijos FIA (pranc. Fédération Internationale de l'Automobile). Tai – brangiausia sporto šaka pasaulyje, savo istoriją skaičiuojanti nuo 1950-ųjų.[lt_LT]\"]\n","6\n","['„Bugatti“ išbandytas ir užgrūdintas lenktyninis hiperautomobilis „Bolide“ gali pasigirti tikra raketa, kurios tikslas – pagerinti oro patekimą į ant stogo esantį ėmiklį, rašo „Car and Driver“.[lt_LT]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_ut9Xeiaw6w","executionInfo":{"status":"ok","timestamp":1617533623002,"user_tz":-180,"elapsed":127993,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"e31cf29f-ad84-43d0-a774-88f181f49002"},"source":["# mbart treniruotas 2 epochas apie 40k tekstu\n","\n","a = [\"Kaip pranešė Policijos departamentas, parlamentaras į policiją kreipėsi apie devintą ryto ir nurodė, kad grasinantį laišką į darbinį elektroninį paštą jis gavo apie penktą valandą ryto. Sostinės policijos atstovė Julija Samorokovskaja BNS sakė, kad E. Sabutis savo pareiškime nurodė, jog laiške grasinama su juo susidoroti dėl to, kad jis yra Seimo narys. Siuntėjo parlamentaras sakė nepažįstantis. Policija pradėjo ikiteisminį tyrimą dėl grasinimo nužudyti ar sunkiai sutrikdyti sveikatą. Laiške prašoma socialinio būsto Laiške, kurį gavo keli parlamentarai rašoma, kad jei asmuo negaus socialinio būsto, „ateisiu pas jus ir subadysiu kaip šunis“. Pateikiame visą laiško tekstą, kalba netaisyta. „Labas Jai jus man neduosite socelinio būso aš ateisiu pas jus ir ir subadisiu kaip šunis galėsite pamatiti daug negyvų žmonių kūnų. Jai duodate sirijos ir Baltarusijos piliečiams kur gyventi tai atsakisite vietos ir man. Kiek aš dar laiko gyvensiu kaip šuva ant gatvės“.\"]\n","b = [\"Dėsnis teigia, kad tam tikromis sąlygomis atsitiktinių veiksnių visuma ilgainiui nulemia rezultatą, nepriklausantį arba mažai priklausantį nuo atsitiktinumo. Tikimybių teorijoje ir matematinėje statistikoje didžiųjų skaičių dėsnis teigia, kad vienodomis sąlygomis daug kartų stebint tą patį atsitiktinį dydį stebėtų reikšmių aritmetinis vidurkis artėja prie tam tikros neatsitiktinės reikšmės, vadinamos stebimojo dydžio (teoriniu) vidurkiu. Kai vienodomis sąlygomis ilgą laiką stebimas tas pats įvykis, kurio pasirodymo tikimybė yra p, didžiųjų skaičių dėsnis teigia, kad to įvykio pasirodymų santykinis dažnis artėja prie p. Pvz., neribotai metant simetrišką monetą santykinis herbo atvirtimų dažnis artėja prie teorinės tokio atvirtimo tikimybės, lygios . Vienas didžiųjų skaičių dėsnio matematinių tikslių formulavimų yra toks: jei X1, X2, …, Xn, …, yra nepriklausomųjų vienodai pasiskirsčiusių atsitiktinių dydžių su vidurkiais EXn = a seka, tai aritmetinis vidurkis (X1 + X2 + ... + Xn)/n artėja prie a, kai n neribotai auga. Pagal artėjimo pobūdį (su tikimybe 1 arba pagal tikimybę) skiriama stiprusis arba silpnasis didžiųjų skaičių dėsnis. Dėsnio apibendrinimai nagrinėja atvejus, kai atsitiktiniai dydžiai nėra vienodai pasiskirstę arba nėra nepriklausomi. Nepriklausomųjų atsitiktinių dydžių sumų ribinę elgseną tiksliau aprašo centrinė ribinė teorema. Atskirą didžiųjų skaičių dėsnio atvejį suformulavo ir 1713 paskelbė J. Bernoullis. 1837 apibendrino ir didžiųjų skaičių dėsnio terminą pirmasis pavartojo S. D. Poissonas. 1867 didžiųjų skaičių dėsnio sąvoką praplėtė P. Čebyšovas.\"]\n","c = [\"Iki šiol kelionės traukiniais buvo landa, kuria žmonės bandydavo apeiti judėjimo ribojimus, nes griežta kontrolė čia netaikyta. Tačiau Velykų savaitgalį šansų prasmukti be patikros nebeliks, o kontrolė pradėta jau ketvirtadienį. „Šiandien mes patikrinsime keleivius vykstančius traukiniu, kalbinsime juos apie buvimą Vilniuje, kokiomis aplinkybėmis jie atsirado Vilniuje, kur jie ruošiasi važiuoti, kalbinsime ir informuosime juos apie Vyriausybės nutarimo reikalavimus dėl karantino laikymosi ir informuosime apie atsakomybę už to nutarimo sąlygų nesilaikymo“, – kalbėjo Vilniaus miesto trečiojo policijos komisariato viršininkas Donaldas Dubaka. Ketvirtadienio popietę į Kauną vykstantį traukinį lipo kelios dešimtys keleivių. Dauguma jų Kauno gyventojai, atvykę į Vilnių darbo ar medicininiais reikalais. Tiesa, vienas patikrintas jaunuolis negalėjo įtikinamai paaiškinti, kodėl lankėsi Vilniuje. „Susitikti su giminaičiu atvažiavau, tiesiog pasikalbėti – pareigūnui aiškino jaunuolis ir pridūrė. – Tai čia savaitgalį turėtų būti ribojimai, savaitgalį tik griežtesni ribojimai.“ Tačiau jis buvo informuotas, kad karantinas galioja visą laiką. Policininkas užsirašė vaikino duomenis ir įspėjo, kad dabar bus atliekamas tyrimas, o jam gresia bauda, nes be rimtos priežasties atvyko į sostinę ir pažeidė judėjimo ribojimus.\"]\n","d = [\"Koronavirusai yra virusai, kurie cirkuliuoja tarp gyvūnų, tačiau žinoma, kad kai kurie iš jų sukelia infekcijas žmonėms. Sukėlę infekciją žmonėms, jie toliau gali būti perduoti nuo žmogaus žmogui. Koronavirusų infekcijos šaltinis gali būti daugybė gyvūnų. Pavyzdžiui, Artimųjų Rytų respiracinio sindromo koronaviruso (MERS-CoV) šaltinis buvo kupranugariai, o sunkaus ūmaus respiracinio sindromo (SŪRS) - civetės katės. Šis naujas Kinijoje aptiktas koronavirusas yra genetiškai glaudžiai panašus į SŪRS sukeliantį virusą. SŪRS atsirado 2002 m. pabaigoje Kinijoje ir per aštuonis mėnesius 33 šalys pranešė apie daugiau nei 8 000 SŪRS atvejų. Tuo metu nuo šio viruso mirė kas dešimtas susirgęs asmuo. Šiuo metu yra per mažai duomenų, kad būtų galima vertinti mirštamumą nuo COVID-19, tačiau preliminarūs duomenys rodo, kad jis yra mažesnis, nei nuo SŪRS. Nors gripo ir COVID-19 perdavimo keliai ir simptomai yra panašūs, šias infekcijas sukeliantys virusai yra labai skirtingi. Dar labai anksti daryti išvadas, kaip plinta naujasis koronavirusas, tačiau išankstinė informacija rodo, kad jo plitimo mechanizmas yra labiau panašus į SŪRS ar pandeminio gripo, negu į sezoninio gripo plitimo mechanizmą, nes žmonės niekada prieš tai nebuvo susidūrę šia infekcija. Europos ligų prevencijos ir kontrolės centro (ECDC) duomenimis, Europoje nuo gripo ir jo sukeltų komplikacijų kasmet miršta apie 40 000 žmonių. Dabartiniai tyrimai sieja COVID-19 su tam tikrais šikšnosparnių tipais, tačiau neatmetama galimybė, kad infekcijos šaltinis galėjo būti ir kiti gyvūnai. Nėra įrodymų, kad tokie naminiai gyvūnai kaip šunys ar katės gali tapti naujojo koronaviruso šaltiniu, tačiau kontaktuojant su gyvūnais rekomenduojama laikytis bendrų higienos principų. \"]\n","e = [\"Burlenčių sportas (kartais vadinamas tiesiog buriavimu) – ekstremalus vandens sportas ir pramoga, kurios pagrindas yra judėjimas vandens paviršiumi panaudojant specialią įrangą, vadinamą burlente. Burlentė yra 2–4 m ilgio plūdrios medžiagos lenta, sujungta su viena bure per lanksčią jungtį. Burlenčių sportas yra buriavimo ir banglenčių sporto hibridas. Burlentė – supaprastintas burinio laivo modelis, kuris vairuojamas palenkiant burę pirmyn arba atgal. Buriuoti burlentėmis galima tiek lygiame vandenyje, tiek bangų mūšoje. Buriavimas burlentėmis yra labai universalus sportas – vieniems tai smagus poilsis prie vandens, kitiems įtemptas lenktyniavimas, dar kitiems – gyvenimo stilius, kurio esmė – tobulos bangos paieškos. Buriavimui reikia ne tiek fizinės jėgos, kiek vikrumo ir lygsvaros. Buriuoti burlentėmis galima esant vėjo greičiui nuo 3 iki 20 m/s, tačiau geriausia, kai vėjo greitis yra tarp 5 ir 15 m/s.\"]\n","f = [\"automobilių sporto lenktynės, organizuojamos Tarptautinės Automobilininkų Federacijos FIA (pranc. Fédération Internationale de l'Automobile) ir laikomos automobilių sporto viršūne. Oficialus pavadinimas – FIA Formulės Vienas Pasaulio Čempionatas (angl. FIA Formula One World Championship). Tai – brangiausia sporto šaka pasaulyje, savo istoriją skaičiuojanti nuo 1950-ųjų. Pirmuoju asmeninės įskaitos čempionu tapo italas Giuseppe Farina, o pirmoji komanda, iškovojusi konstruktorių taurę (įsteigtą 1958 m.) – Vanwall ekipa. Sėkmingiausias F1 pilotas, kuriam priklauso beveik visi rekordai – vokietis Michaelis Schumacheris, tarp ekipų išsiskiria italų Ferrari (tai vienintelė komanda, lenktyniaujanti nuo pat pirmojo 1950-ųjų m. sezono) komanda.\"]\n","g = [\"Bet meskim visus išvedžiojimus ir eikim tiesiai prie įspūdingų skaičių. Išbandytas ir užgrūdintas 8 litrų variklis generuoja 1578 arklio galias (1177 kW), kaip galėjome įsitikinti, skriedami „Centodieci“ arba „Super Sport 300+“ modeliais. Tačiau „Bugatti“ ties tuo nesustojo ir perkonstravo šį variklį taip, kad jį būtų galima „maitinti“ lenktyniniais degalais, kurių oktaninis skaičius siekia 110. Šis patobulinimas leido pasiekti stulbinamas 1825 AG (1361 kW), esant 7 tūkst. aps./min. ir 1850 niutonmetrų sukimo momentą, esant 2 tūkst. aps./min. Galios šuolis taip pat buvo pasiektas sukūrus naujus keturgubus turbokompresorius.Taikydami įvairias svorio taupymo priemones, inžinieriai iš Molsheimo sugebėjo sumažinti „Bolide“ svorį iki 1240 kilogramų arba maždaug tiek, kiek sveria įprastas europietiškas kompaktiškas automobilis.Nenuostabu, kad toks galingas ir tiek nedaug sveriantis lenktyninis hiperautomobilis yra tikra raketa. Nuo 0 iki 100 km/val. jis įsibėgi vos per 2,17 sekundes, o 200 km/val. greitį pasiekia per 4,36 sekundes. Bet nepamirškite, kad kol kas „Bugatti“ neatliko šių pagreičio testų realiomis sąlygomis – visa tai tėra simuliacijose gauti rezultatai. Tas pats pasakytina ir apie įsibėgėjimą nuo 0 iki 300 km/val. per 7,37 sekundes bei iki 400 km/val. per 12,08 sekundes.„Bugatti“ netgi pateikė teorinį įsibėgėjimo nuo 0 iki 500 km/val. laiką, kuris siekia 20,16 sekundes. Kitaip tariant, „Bolide“ Niurnburgringo trasą turėtų įveikti per 5 minutes ir 23,1 sekundes. Maksimalus greitis? „Gerokai virš 500 km/val.“, o „Le Mano“ rato įveikimo laikas užfiksuotas ties 3 minutėmis ir 7,1 sekundėmis. Vėlgi visa tai tėra simuliacijų rodikliai.Nevertėtų pamiršti ir dizaino. Tik pažiūrėkite į jį. Jei manėte, kad „Bugatti Vision Gran Turismo“ yra iš kito pasaulio, tai „Bolide“ neabejotinai atskriejęs iš tolimos galaktikos. Iš tikrųjų čia slypi kur kas daugiau dalykų, nei galima įžiūrėti plika akimi. Naujasis automobilis gali pasigirti „transformuojama oda“ (kaip „Bugatti“ tai vadina), kurios tikslas – pagerinti oro patekimą į ant stogo esantį ėmiklį. Važiuojant lėtai, ėmiklio paviršius išlieka lygus, tačiau kiek stipriau spustelėjus akceleratorių, jis išsiplečia.Oficialios automobilio nuotraukos ne visiškai tiksliai atspindi jo prošvaisą, kuri siekia vos 995 mm ir yra maždaug 300 mm mažesnė nei įprastas „Chiron“ aukštis. Dėl X formos priekinių ir galinių žibintų „Bolide“ atrodo kaip ką tik išriedėjęs iš mokslinės fantastikos filmo.Vos per 9 mėnesius sukurtas „Bolide“ kol kas nėra įvertintas pinigine išraiška. Taip yra dėl to, kad „Bugatti“ vis dar svarsto, ar verta pradėti šio „aukščiausios klasės vidaus degimo variklio“ gamybą.\"]\n","\n","\n","lst = [a,b,c,d,e,f, g]\n","summ = []\n","for i,txt in enumerate(lst):\n","  print(i)\n","  translation = bart.sample(txt, beam=4, lenpen=2.0, max_len_b=140, min_len=55, no_repeat_ngram_size=3)\n","  print(translation)\n","  \n","  summ.append(translation)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","['Lietuvos socialdemokratų partijos (LSDP) frakcijos narys Eugenijus Sabutis pirmadienį gavo laišką, kuriame grasinama nužudyti ir sunkiai sutrikdyti sveikatą, o jei asmuo negaus socialinio būsto, jis bus subadytas kaip šunis.[lt_LT]']\n","1\n","['Didžiųjų skaičių dėsnis teigia, kad tam tikromis sąlygomis atsitiktiniai dydžiai nėra vienodai pasiskirstę arba nėra nepriklausomi nuo atsitiktinumo, rašoma pranešime žiniasklaidai. Dėsnio apibendrinimai nagrinėja atvejus, kai vienodomis sąlygomis ilgą laiką stebimas tas pats įvykis, kurio pasirodymo tikimybė yra p.[lt_LT]']\n","2\n","['į traukinį lipo kelios dešimtys keleivių. Dauguma jų atvykę į Vilnių darbo ar medicininiais reikalais, o vienas į Kauną atvykęs jaunuolis negalėjo įtikinamai paaiškinti, kodėl atvyko į sostinę ir pažeidė karantino reikalavimus.[lt_LT]']\n","3\n","['koronavirusas yra genetiškai glaudžiai panašus į gripo sukeliantį virusą, tačiau žmonės niekada prieš tai nebuvo susidūrę šia infekcija, rašoma pranešime spaudai, remdamasis Europos ligų prevencijos ir kontrolės centro (ECDC).[lt_LT]']\n","4\n","['Burlenčių sportas (kartais vadinamas tiesiog buriavimu) – ekstremalus vandens sportas ir pramoga, kurios pagrindas yra judėjimas vandens paviršiumi panaudojant specialią įrangą, vadinamą burlente. Burlentė yra 2–4 m ilgio plūdrios medžiagos lenta, sujungta su viena bure.[lt_LT]']\n","5\n","['Formulės Vienas Pasaulio Čempionatas (angl. FIA Formula One World Championship) – automobilių sporto šaka, skaičiuojanti savo istoriją nuo 1950-ųjų, skelbiama pranešime žiniasklaidai. Tai – brangiausias ir vienintelis toks čempionatas pasaulyje, skaičiuojantis savo istoriją.[lt_LT]']\n","6\n","['„Bugatti“ jau trečią kartą iš eilės pristato „Bolide“ koncepciją, kuri yra tarsi kelionė laiku ir gali nustebinti kiekvieną vairuotoją. Nepaisant to, kad šis automobilis atrodo tarsi nužengęs iš fantastinio filmo, jo išvaizdos taip pat neatspindi realaus pagreičio, rašo „Motor 1.com“.[lt_LT]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZx27wFlbg0j","executionInfo":{"status":"ok","timestamp":1617533677951,"user_tz":-180,"elapsed":28405,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"f0176ef9-0d78-4318-d3ae-f1669e26e8aa"},"source":["test_article = [\"Susitelkti teko visiems Praeitos savaitės pabaigoje progimnazijos Tėvų tarybos pirmininkas Arūnas Penkaitis sakė, kad grįžimo į mokyklą laukiama kaip šventės, kaip gimtadienio: „Anksčiau, kai išties turėjome tam tikrą informacijos trūkumą, nuotaikų buvo įvairių. Šiuo metu, gavus atsakymus į visus kilusius klausimus, didžioji dauguma bendruomenės nusiteikusi labai pozityviai.“ Mokyklos direktorius R.Remeika praėjusią savaitę 15min teigė, kad nuotolinis ugdymas nėra toks efektyvus, todėl siekiama kuo greičiau pereiti į kontaktinį mokymą. Pirmadienio rytą jis feisbuke džiaugėsi, kad bendruomenė susitelkė ir atsakingai dirbdama parodė, kiek daug vaikų labui gali padaryti. O ši savaitė taip pat būsianti susitelkimo metas, kai teks griežtai laikytis visų saugumo taisyklių tiek mokykloje, tiek namuose, tiek viešoje erdvėje, nes esą nėra „prabangos“ susirgti ir taip rizikuoti aplinkinių sveikata. Rezultatus vertins po dar vienų testų Anot Vilniaus mero Remigijaus Šimašiaus, prieš grįžtant į klases buvo testuojami ir darbuotojai, ir mokiniai, ir jų šeimų nariai, tad iššūkių netrūko. „Savaitės pabaigoje vėl bus atliekami testai, žiūrėsime, kokie rezultatai. Nes patys suprantame, kad švietimas yra ta sritis, kur labai norisi grįžti į normalias vėžes ir dar geresnes – per pandemiją išmoko naujų dalykų ir mokytojai, ir mokiniai. Kartu suprantame tą riziką – iš Estijos gavome ataskaitą, kad mokyklose didelė rizika, vaikai vieni kitiems perneša. Mūsų tą eksperimentą Lietuvos mastu traktuoju kaip labai svarbų – kaip organizuoti ir kaip paskui viskas vyks“, – kalbėjo R.Šimašius. Mero teigimu, jeigu reikėtų pagal tokią pačią procedūrą atidaryti visas Lietuvos ar Vilniaus mokyklas, tai greičiausia nebūtų įmanoma – resursų niekam ir niekada neužtektų. Todėl reikia apibendrinti išvadas, kaip tai galima padaryti paprasčiau. Apie tai ketinama diskutuoti ir su Vyriausybe. Atsidarytų nors rytoj Paklaustas, kada galėtų visos mokyklos atsidaryti, meras sakė, kad jeigu virusas iš Lietuvos išeitų, tai galima būtų ir rytoj padaryti. „Bet kada jis išeis, kokiu tempu, kokios variacijos, kiti dalykai, negaliu pasakyti. Bet jeigu epidemiologinė situacija leistų, sugrįžti į mokyklas mums nebūtų problemų. Nebent kiltų vienai kitai šeimai, nes ne paslaptis, kad ne vienas moksleivis, kartais ir mokytojai pamokose dalyvauja ne iš Vilniaus, kartais net ir į užsienį išvažiavę“, – sakė R.Šimašius. Jis įsitikinęs, kad tokių ar panašių eksperimentų turėtų būti ir daugiau, tai leistų lengviau grįžti visiems, kai epidemiologinė situacija leis. Vilnius rengė konferenciją su mokytojais, svarstė nuotolinio mokymosi sąlygas ir būdus, tai joje paaiškėjo, kad tiek abiturientai, tiek mokytojai vieningai sako, kad egzaminų vėlinti negalima ir nereikia, yra pasiūlymų, kaip organizuoti juos tinkamai įprastu metu. Buvo teigiamų testų Vilniaus visuomenės sveikatos biuro vadovė Guoda Ropaitė-Beigė teigė, kad viso šio proceso metu mokyklos bendruomenė buvo itin aktyvi: „Ketvirtadienį startavome su pedagogų testavimu kaupinių principu, tai 93 asmenys, sudarėme 39 kaupinius, visi buvo neigiami. Tai tikrai mokytojai saugūs ir sveiki grįžo į šitą įstaigą. O kalbant apie namų ūkius – t. y. vaikus ir jų tėvelius, testavimas vyko penktadienį, šeštadienį ir dar sudarėme galimybę ir sekmadienį testuotis. Buvo per 500 kaupinių, daugiau nei 2 tūkst. asmenų atvyko testuotis į testavimo punktą, keturi kaupiniai buvo teigiami, dabar vykdomi tyrimai PGR tyrimai.“ Šis testavimo būdas skiriasi nuo PGR tuo, kad pastarojo atveju imamas mėginys iš nosiaryklės ir ryklės, o kaupinio – iš nosies landų ir tie ėminiai grupuojami: vienoje virusologinėje terpėje grupuojami ir dedami kelių asmenų ėminius ir jie tiriami.\"]\n","\n","translation = bart.sample(test_article, beam=4, lenpen=2.0, max_len_b=140, min_len=55, no_repeat_ngram_size=3)\n","print(translation)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Pirmadienio popietę Vilniaus progimnazijos direktorius Remigijus Remeika feisbuke džiaugėsi, kad bendruomenė susitelkė ir atsakingai dirbdama parodė, kiek daug vaikų labui gali padaryti, o ši savaitė taip pat busianti susitelkimo metas, kai teks griežtai laikytis visų saugumo taisyklių tiek mokykloje, tiek namuose, tiek viešoje erdvėje, nes esą nėra „prabangos“.[lt_LT]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mOF87fg2iBSB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617533415265,"user_tz":-180,"elapsed":23152,"user":{"displayName":"Robert Tarasevič","photoUrl":"","userId":"09001954571379926305"}},"outputId":"6460da23-8393-4370-a178-5c03e3e96370"},"source":["test_article = [\"\"\"\n","Oficialiosios statistikos įstaigos, įvairios valstybės tarnybos, medicinos įstaigos, mobiliojo ryšio operatoriai, bankai, transporto ir kitų verslo sričių įmonės, socialiniai tinklai, žaidimų portalai ir didžiulė įvairovė kitų internete veikiančių ir paslaugas teikiančių svetainių sukaupia milžiniškus kiekius duomenų.\n","Be to, atsiranda vis daugiau  išmaniųjų įrenginių, kurie taip pat generuoja didžiulius kiekius įvairios prigimties duomenų. Jų analizė tampa didele problema. Norint iš turimų duomenų gauti prasmingos ir naudingos informacijos verslui, reikia naujos kartos analitikų, gebančių taikyti šiuolaikinius analizės ir prognozavimo metodus, technologijas ir analitikos programines priemones.\n","Tai – taikomosios statistikos specialisto darbas, kuris šiuolaikiniame pasaulyje vis reikalingesni.\n","Į Taikomosios statistikos magistro studijų programą gali stoti statistikos, matematikos arba informatikos bakalauro kvalifikacinį laipsnį turintys studentai.\n","Baigus studijas suteikiamas matematikos mokslų magistro laipsnis.\n","Taikomosios statistikos magistro studijų programoje galima rinktis vieną iš dviejų specializacijų: Duomenų mokslą arba Statistinius metodus finansuose ir ekonomikoje.\n","Duomenų mokslo specializacija orientuota į duomenų analizės specialistų rengimą.\n","Analizuojant ypač didelius duomenų kiekius susiduriama su specifinėmis problemomis, kokių tradicinėje statistikoje iš esmės nėra. Pirmiausia, tai įvairios problemos, kylančios dėl fizinės duomenų apimties. Dėl tos pačios priežasties smarkiai išauga duomenų apdorojimo laikas.\n","Kita aktuali problema yra ta, kad labai dažnai duomenys yra nestruktūrizuoti, todėl tradicinių statistinės analizės metodų tiesiogiai pritaikyti negalima. Be to, atsiranda tokių uždavinių, kuriems reikia naujų duomenų analizės metodų.\n","Tai paskatino naujos tarpdisciplininės mokslo srities – duomenų mokslo (angl. Data Science) – vystymąsi.\n","Kvalifikuotai didelės apimties duomenų analizei reikalingi tokie specialistai, kurie mokėtų programuoti, turėtų žinių apie duomenų bazes ir kitas su duomenų apdorojimu susijusias informacines technologijas. Be to, žinotų ir mokėtų taikyti statistinės analizės, statistinio modeliavimo bei prognozavimo metodus. Tokių specialistų poreikis tik didėja.\n","Statistinių metodų finansuose ir ekonomikoje specializacija yra skirta rengti šiuolaikinius duomenų analizėje taikomus modelius ir metodus išmanančius bei būtiniausių darbo su realia statistine informacija įgūdžių turinčius specialistus.\n","Programa atitinka taikomosios ekonometrijos pakraipą ir yra aktuali, kadangi  Lietuvoje itin stinga šios srities specialistų. Šiuolaikiniame versle statistinės analizės svarba nuolat auga, o reikiamos kvalifikacijos profesionalų Lietuvoje yra nedaug.\n","Programos tikslas – rengti aukštos kvalifikacijos specialistus, gebančius matematinės statistikos metodais atlikti svarbių ir aktualių Lietuvai ekonominio ir techninio pobūdžio duomenų analizę, prekių ir paslaugų kainų dinamikos analizę ir prognozę, šiuolaikiniais statistikos metodais nustatyti optimalių draudimo įnašų dydžius ir t. t.\n","\"\"\"\n","]\n","\n","translation = bart.sample(test_article, beam=4, lenpen=2.0, max_len_b=140, min_len=55, no_repeat_ngram_size=3)\n","print(translation)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['ikonominės, finansinės, socialinės ir politikos srityse dirbantys specialistai turi žinių apie duomenų bazes ir kitas su duomenų apdorojimu susijusias informacines technologijas. Tai – taikomosios statistikos magistro studijų programos dalis, kurioje galima rinktis vieną iš dviejų specializacijų: Duomenų mokslą arba Statistinius metodus finansuose ir ekonomikoje.[lt_LT]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ByLtR1-e6AYl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9EiSXA9VHV5z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bpH1BsxvHV77"},"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizerfrom nltk import sent_tokenize, word_tokenize"],"execution_count":null,"outputs":[]}]}